Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_intro", "api_ref_kernel", "api_ref_quantization", "api_ref_sparsity", "contributor_guide", "dtypes", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_nf4", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_floatx", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.dequantize_affine_floatx", "generated/torchao.quantization.fake_quantize_affine", "generated/torchao.quantization.fake_quantize_affine_cachemask", "generated/torchao.quantization.float8_dynamic_activation_float8_weight", "generated/torchao.quantization.float8_static_activation_float8_weight", "generated/torchao.quantization.float8_weight_only", "generated/torchao.quantization.fpx_weight_only", "generated/torchao.quantization.int4_weight_only", "generated/torchao.quantization.int8_dynamic_activation_int4_weight", "generated/torchao.quantization.int8_dynamic_activation_int8_weight", "generated/torchao.quantization.int8_weight_only", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.quantize_affine_floatx", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.quantization.uintx_weight_only", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "getting-started", "index", "overview", "performant_kernels", "quantization", "serialization", "sg_execution_times", "sparsity", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial"], "filenames": ["api_ref_dtypes.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "contributor_guide.rst", "dtypes.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_floatx.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.dequantize_affine_floatx.rst", "generated/torchao.quantization.fake_quantize_affine.rst", "generated/torchao.quantization.fake_quantize_affine_cachemask.rst", "generated/torchao.quantization.float8_dynamic_activation_float8_weight.rst", "generated/torchao.quantization.float8_static_activation_float8_weight.rst", "generated/torchao.quantization.float8_weight_only.rst", "generated/torchao.quantization.fpx_weight_only.rst", "generated/torchao.quantization.int4_weight_only.rst", "generated/torchao.quantization.int8_dynamic_activation_int4_weight.rst", "generated/torchao.quantization.int8_dynamic_activation_int8_weight.rst", "generated/torchao.quantization.int8_weight_only.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.quantize_affine_floatx.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.quantization.uintx_weight_only.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "getting-started.rst", "index.rst", "overview.rst", "performant_kernels.rst", "quantization.rst", "serialization.rst", "sg_execution_times.rst", "sparsity.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst"], "titles": ["torchao.dtypes", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization", "torchao.sparsity", "torchao Contributor Guide", "Dtypes", "AffineQuantizedTensor", "NF4Tensor", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_nf4", "MappingType", "TorchAODType", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_floatx", "choose_qparams_affine_with_min_max", "choose_qparams_and_quantize_affine_hqq", "dequantize_affine", "dequantize_affine_floatx", "fake_quantize_affine", "fake_quantize_affine_cachemask", "float8_dynamic_activation_float8_weight", "float8_static_activation_float8_weight", "float8_weight_only", "fpx_weight_only", "int4_weight_only", "int8_dynamic_activation_int4_weight", "int8_dynamic_activation_int8_weight", "int8_weight_only", "int_scaled_matmul", "quantize", "quantize_affine", "quantize_affine_floatx", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "uintx_weight_only", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "Getting Started", "Welcome to the torchao Documentation", "Overview", "Performant Kernels", "Quantization", "Serialization", "Computation times", "Sparsity", "&lt;no title&gt;", "Computation times", "Template Tutorial"], "terms": {"thi": [1, 5, 7, 8, 15, 18, 19, 21, 23, 25, 26, 30, 31, 32, 36, 37, 44, 45, 46, 52, 57], "section": [1, 5], "introduc": [1, 5], "dive": 1, "detail": [1, 5, 18, 30], "how": [1, 7, 15, 19, 31, 37, 52], "integr": [1, 52], "pytorch": [1, 7, 16, 48, 57], "optim": [1, 18, 22, 36, 48], "your": [1, 5, 36], "machin": 1, "learn": [1, 31, 57], "model": [1, 18, 32, 36, 40, 41, 45, 46], "dtype": [1, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 36, 37, 43, 48, 52], "quantiz": [1, 7, 8, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 48, 52], "sparsiti": [1, 5, 44, 45, 46, 48, 52], "tba": [2, 6, 47, 49, 50, 51, 54], "In": 5, "doc": 5, "we": [5, 7, 8, 15, 18, 19, 21, 23, 25, 36, 37, 43, 52], "ll": [5, 15, 19], "talk": 5, "about": [5, 31, 52], "1": [5, 15, 16, 17, 18, 19, 22, 31, 36, 37, 43, 45, 52, 53, 56, 57], "differ": [5, 21, 31, 37, 39, 52], "techniqu": [5, 52], "ar": [5, 7, 18, 19, 23, 25, 27, 30, 31, 36, 37, 39, 45, 52], "2": [5, 7, 15, 18, 19, 26, 31, 36, 37, 46, 57], "contribut": [5, 48], "note": [5, 26, 45], "heavili": 5, "focus": 5, "infer": [5, 7, 40, 48, 52], "right": 5, "now": [5, 30, 32], "plan": 5, "expand": 5, "cover": [5, 57], "futur": [5, 30], "well": [5, 18], "first": [5, 8, 18, 35, 45], "want": [5, 36, 52], "lai": 5, "out": [5, 15, 18, 45], "hqq": [5, 31, 43], "awq": 5, "gptq": 5, "etc": 5, "affinequantizedtensor": [5, 52], "codebookquantizedtensor": 5, "matmul": [5, 29], "dequant": [5, 7, 8, 23, 31], "uint1": [5, 43], "uint7": [5, 43], "int1": 5, "int8": [5, 8, 32, 33, 34, 36], "float3": 5, "float8": [5, 27, 28, 29], "ani": [5, 18, 42, 45], "some": [5, 18, 36, 45], "compon": 5, "from": [5, 7, 8, 19, 21, 23, 25, 30, 32, 36, 37, 52, 53, 56, 57], "abov": [5, 15, 52], "int4_weight_onli": [5, 36, 52], "tinygemm": [5, 31, 36], "bf16": [5, 19], "quant": [5, 7, 30], "3": [5, 15, 18, 19, 37, 57], "tensorcoretiledlayout": [5, 31], "4": [5, 19, 22, 46, 52], "uint4": [5, 31, 36], "simul": [5, 46], "quant_min": [5, 7, 12, 13, 15, 19, 21, 23, 25, 26, 37], "quant_max": [5, 7, 12, 13, 15, 19, 21, 23, 25, 26, 37], "also": [5, 18, 36, 52], "overload": 5, "term": 5, "mean": [5, 7, 8, 15, 19, 23, 25, 37, 38], "make": [5, 19], "sens": 5, "without": [5, 19, 25, 26], "extra": 5, "metadata": 5, "e": [5, 7, 15, 18, 19, 23, 25, 30, 36, 37, 38, 52], "g": [5, 7, 15, 18, 19, 23, 25, 30, 36, 37, 52], "when": [5, 7, 19, 23, 25, 37], "peopl": [5, 52], "call": [5, 7, 18, 25, 26, 36, 44, 52], "empti": 5, "more": [5, 18, 26, 30, 31, 32, 43], "pleas": [5, 7, 30, 31, 48], "check": [5, 7, 52], "dev": 5, "discuss": 5, "org": [5, 18, 30, 45], "t": [5, 19, 45], "1833": 5, "No": [5, 52], "matter": 5, "what": [5, 7, 18, 57], "do": [5, 16, 18, 19, 35, 36], "end": [5, 57], "precis": [5, 7, 29, 38], "repres": [5, 7, 37, 45, 52], "data": [5, 7, 21, 27, 28, 29, 48, 52], "aim": 5, "uint8": [5, 23, 37], "avail": 5, "later": 5, "6": [5, 36], "float3_e2_m0": 5, "float4_e2_m1": 5, "float4_e3_m0": 5, "float5_e2_m2": 5, "float5_e3_m1": 5, "float6_e2_m3": 5, "float6_e3_m2": 5, "float8_e4m3fn": [5, 27, 28, 29], "float8_e5m2": 5, "float8_e4m3fnuz": 5, "float8_e5m2fnuz": 5, "float4": 5, "float6": 5, "thei": 5, "becom": 5, "popular": 5, "prototyp": 5, "consid": [5, 39], "core": [5, 16], "have": [5, 15, 18, 19, 31, 37, 45], "hardwar": 5, "actual": [5, 29], "two": [5, 27], "part": 5, "need": [5, 19, 27, 44, 45, 52], "uint2": 5, "117208": 5, "just": [5, 15, 52], "so": [5, 18, 52], "can": [5, 15, 18, 27, 36, 37, 52], "outsid": 5, "standard": 5, "pack": [5, 7, 30, 43], "format": [5, 7, 8, 30, 38], "As": 5, "mention": 5, "criteria": 5, "show": [5, 37], "wide": 5, "adopt": 5, "For": [5, 19, 30, 52], "fundament": 5, "ones": [5, 45], "type": [5, 7, 8, 15, 16, 17, 18, 22, 27, 28, 29, 31, 32, 35, 37, 39, 48, 52], "wait": [5, 18], "until": 5, "evid": 5, "requir": [5, 19], "decid": 5, "hopefulli": 5, "one": [5, 18, 21, 27, 44], "amen": 5, "both": [5, 27], "uintx": [5, 43], "floatx": 5, "haven": 5, "enough": 5, "ont": 5, "final": [5, 18, 26, 36], "revisit": 5, "after": [5, 18, 52], "intx": 5, "being": [5, 41], "connect": 5, "creat": [5, 7], "int4tensor": 5, "previou": 5, "step": [5, 18], "convert": [5, 7, 8, 36, 38], "between": 5, "preicison": 5, "mainli": 5, "follow": [5, 31], "choose_qparam": [5, 7], "choos": 5, "paramet": [5, 8, 15, 18, 19, 23, 25, 27, 28, 29, 31, 32, 35, 36, 37, 39, 40, 41, 43, 45, 52], "base": [5, 15, 45], "origin": [5, 7, 8, 25, 29, 37, 45, 52], "typic": [5, 8, 19, 52], "scale": [5, 7, 10, 13, 15, 17, 19, 21, 23, 24, 25, 26, 28, 35, 37, 38, 40, 41], "zero_point": [5, 7, 13, 17, 19, 21, 23, 25, 26, 31, 37], "affin": [5, 7, 23, 25, 36, 37], "There": 5, "could": 5, "variat": 5, "accommod": 5, "specif": [5, 45, 52], "mai": [5, 21, 52], "choose_qparams_affine_with_min_max": 5, "min": 5, "max": [5, 15], "valu": [5, 7, 8, 15, 16, 17, 18, 19, 23, 25, 26, 37, 40, 45], "process": [5, 18, 41, 57], "_weight_int4pack_mm": [5, 31], "int_matmul": 5, "take": [5, 8, 36, 44], "output": [5, 18, 19, 23, 25, 37, 57], "an": [5, 7, 18, 26, 45, 48], "int32": [5, 36], "int_scaled_matmul": 5, "doe": [5, 31], "appli": [5, 18, 27, 28, 29, 31, 32, 33, 34, 36, 43], "result": [5, 18, 35, 38, 39], "reli": 5, "through": [5, 21, 57], "get": [5, 8], "speedup": [5, 31], "s": [5, 7, 15, 18, 19, 23, 25, 37, 38], "correspond": [5, 19, 36, 52], "On": 5, "top": 5, "glue": 5, "everyth": 5, "togeth": 5, "build": 5, "construct": 5, "configur": [5, 27, 28], "user": [5, 18, 57], "sinc": [5, 44, 52], "like": [5, 18, 19, 52], "exist": [5, 16], "map": [5, 15, 19], "low_precision_v": 5, "high_precision_v": 5, "where": [5, 15, 21, 38, 43], "calcul": [5, 8, 15, 19, 21, 40], "procedur": 5, "veri": 5, "common": 5, "straightforward": 5, "try": 5, "higher": 5, "lower": [5, 32], "transform": [5, 7], "high_preicsion_v": 5, "anoth": 5, "especi": [5, 52], "bitwidth": 5, "than": 5, "codebook": 5, "look": [5, 7], "up": [5, 8, 36], "tabl": [5, 37], "hardcod": 5, "list": [5, 18, 23, 41, 45], "select": 5, "most": 5, "stride": [5, 7], "provid": [5, 18, 19], "multi": 5, "dimension": 5, "view": 5, "storag": [5, 7], "spars": [5, 45], "mkldnn": 5, "coo": 5, "ha": [5, 7], "sparse_coo": 5, "sparsetensorimpl": 5, "which": [5, 18, 52], "chang": [5, 36, 52], "store": [5, 7, 8, 44], "The": [5, 7, 18, 27, 28, 29, 30, 35, 36, 39, 40, 41, 45, 48, 52], "idea": 5, "fit": [5, 52], "nice": 5, "concept": [5, 57], "reus": 5, "And": [5, 8, 27], "python": [5, 55, 57], "modifi": [5, 36, 45], "c": 5, "friendli": 5, "tensor_impl": [5, 7], "unpack": [5, 8, 38], "relev": [5, 31, 57], "class": [5, 7, 8, 15, 16, 17, 18, 44, 45, 52], "conflict": 5, "properti": 5, "_layout": [5, 9, 10, 11, 12, 13], "def": [5, 36, 52], "self": [5, 7, 52], "return": [5, 7, 8, 18, 26, 35, 36, 39, 40, 41, 52], "abstract": 5, "represent": [5, 7, 19, 31], "interact": 5, "same": [5, 7, 19, 21, 23, 25, 26, 27, 37, 39], "run": [5, 18, 36, 40, 44, 57], "transpos": 5, "quantized_linear": 5, "semant": 5, "should": [5, 7, 19, 23, 25, 37, 44, 45], "stai": 5, "util": [5, 52], "help": 5, "below": [5, 57], "tradition": 5, "see": [5, 7, 30, 52], "come": 5, "demonstr": 5, "purpos": 5, "let": [5, 15, 37], "sai": [5, 15, 37], "to_affine_quant": 5, "simplic": 5, "float": [5, 7, 8, 12, 15, 17, 18, 19, 21, 22, 23, 25, 26, 30, 31, 36, 37, 38, 41, 45, 52], "point": [5, 7, 15, 17, 19, 23, 25, 30, 31, 37, 38, 52], "target_dtyp": [5, 9, 10, 12, 13, 19, 21], "all": [5, 15, 18, 21, 44, 45, 46, 52, 53, 55], "explain": 5, "introduct": [5, 48], "found": 5, "simplest": 5, "form": 5, "easi": 5, "linear_modul": 5, "nn": [5, 18, 36, 40, 41, 52], "to_affine_quantized_intx": [5, 36], "requires_grad": [5, 36], "fals": [5, 7, 12, 18, 22, 31, 36, 40, 43, 45, 52], "linear": [5, 18, 19, 27, 29, 31, 32, 33, 34, 36, 41, 43, 46, 52], "befor": [5, 36, 52], "runtim": 5, "compar": [5, 26, 31, 45], "main": [5, 7, 31], "question": [5, 52], "pattern": 5, "to_linear_activation_quant": 5, "quantized_weight": 5, "activation_and_weight_quant": 5, "input_quant_func": [5, 42], "encount": 5, "f": [5, 52], "input_qunat_func": 5, "redispatch": 5, "If": [5, 7, 18, 19, 27, 35, 39, 40, 45], "swap": 5, "fx": 5, "symbolic_trac": 5, "trace": 5, "you": [5, 36, 45, 52, 57], "But": [5, 19], "prefer": 5, "becaus": [5, 52], "easier": 5, "deseri": 5, "directli": [5, 15, 21], "further": 5, "prepar": [5, 18, 40, 45], "otherwis": [5, 7], "d": 5, "modif": 5, "instead": [5, 21, 31, 44], "sampl": 5, "order": [5, 18], "figur": 5, "appropri": [5, 45], "At": 5, "three": [5, 7, 18, 45], "input": [5, 7, 8, 18, 19, 21, 23, 25, 26, 35, 36, 37, 39, 45], "collect": 5, "statist": [5, 45], "thing": [5, 52], "address": 5, "stat": 5, "track": [5, 21], "move": [5, 36], "averag": 5, "forward": [5, 18, 44, 52], "calculate_qparam": 5, "affinequantizedminmaxobserv": 5, "record": [5, 18], "min_val": [5, 21], "max_val": [5, 21], "granular": [5, 7, 19, 23, 25, 27, 28, 31, 32, 37, 43], "interest": 5, "insert_observer_": 5, "api": [5, 18], "handl": [5, 18], "altern": 5, "observedlinear": 5, "non": [5, 18], "dataset": 5, "complic": 5, "them": [5, 18, 44], "next": 5, "quantize_": [5, 36, 52], "apply_tensor_subclass": [5, 36], "done": 5, "manner": 5, "intend": 5, "autoround": 5, "multitensor": 5, "hook": [5, 44], "sure": [5, 19], "wai": [5, 7, 18], "feel": 5, "free": 5, "open": 5, "issu": 5, "describ": [5, 52, 57], "advis": 5, "todo": 5, "todai": 5, "low_bit_optim": 5, "8": [5, 15, 19, 31], "fsdp": 5, "similar": 5, "quantized_train": 5, "initi": [5, 7, 52], "enabl": 5, "progress": 5, "lot": 5, "includ": 5, "checkout": [5, 7, 48], "tutori": [5, 53, 55, 56], "trainabl": 5, "To": [5, 7, 18, 52], "here": [5, 7, 37, 48, 52], "walk": [5, 57], "happen": [5, 7, 18], "quantize_affin": [5, 7, 25, 26, 31], "_convert_weight_to_int4pack": 5, "aten": [5, 31], "start": [5, 15, 16, 17, 18], "asymmetr": [5, 15, 19, 31, 32, 36, 43], "per": [5, 7, 19, 23, 25, 29, 31, 32, 33, 34, 37, 43, 45], "group": [5, 31, 32, 43], "tensor_core_til": [5, 31], "convers": [5, 7, 36], "second": [5, 18, 35, 57], "argument": [5, 7, 18, 23, 36], "choose_qparams_affin": [5, 7, 21, 31], "tile": 5, "tensorcoretiledaqttensorimpl": 5, "bia": [5, 52], "bfloat16": [5, 8, 25, 36, 37, 52], "__torch_function__": 5, "weight_tensor": 5, "_quantized_linear_op": 5, "input_tensor": [5, 8], "goe": 5, "_aqt_qlinear_dispatch_t": 5, "each": [5, 8, 18, 40, 44], "condit": 5, "pass": [5, 18, 21, 44], "explan": 5, "dispatch_condit": 5, "impl": [5, 7], "wint4": 5, "still": 5, "focu": [5, 48], "extens": 5, "flexibl": 5, "fine": [5, 31, 32, 43], "tune": 5, "autograd": 5, "distribut": 5, "scenario": 5, "extern": [5, 7], "resourc": 5, "edward": 5, "podcast": 5, "zoo": 5, "multipl": [5, 18, 27, 28, 35, 39], "motiv": 5, "recommend": [5, 18, 36], "approach": 5, "It": 5, "natur": 5, "alreadi": [5, 7, 18], "intercept": 5, "comput": [5, 29, 44, 45], "long": 5, "abl": 5, "allow": 5, "variant": [5, 15, 21], "slightli": 5, "version": 5, "compat": 5, "would": 5, "combin": [5, 18], "back": 5, "clarif": 5, "document": 5, "A": [5, 7, 18, 21, 26, 44], "few": 5, "method": [5, 18, 36, 45], "__new__": 5, "__init__": [5, 52], "__tensor_flatten__": 5, "__tensor_unflatten__": 5, "__torch_dispatch__": 5, "http": [5, 7, 18, 30, 45], "github": [5, 7, 30], "com": [5, 7, 30], "ao": [5, 7], "blob": [5, 7], "e283743b3cc4612bb641b88dca3670231724d396": 5, "py": [5, 7, 53, 56, 57], "l437": 5, "import": [5, 19, 36, 52, 57], "torchaobasetensor": 5, "mydtypelayout": 5, "mydtypetensor": 5, "instanc": [5, 36, 44, 52], "must": 5, "_make_wrapper_subclass": 5, "cl": 5, "shape": [5, 7, 18, 35, 39], "staticmethod": 5, "size": [5, 7, 8, 19, 23, 25, 31, 32, 37, 43, 52], "option": [5, 7, 9, 12, 13, 18, 19, 21, 23, 25, 26, 27, 28, 36, 37, 40, 41, 42, 45], "none": [5, 7, 9, 12, 13, 15, 16, 17, 18, 19, 21, 23, 25, 26, 27, 28, 34, 36, 37, 40, 41, 42, 45], "kwarg": [5, 7, 44, 45, 46], "ignor": [5, 44], "attr": 5, "desugar": 5, "attribut": 5, "reconstruct": 5, "3bc2004f9123a32f381ef64202252d59109507f3": 5, "_python_dispatch": 5, "l289": 5, "outer_s": 5, "outer_strid": 5, "classmethod": 5, "tensor_data_dict": 5, "tensor_attribut": 5, "els": 5, "fp32": [5, 19, 23], "fp16": [5, 19], "from_float": 5, "input_float": [5, 9, 10, 11, 12, 13, 42], "mapping_typ": [5, 12, 19, 21, 32], "mappingtyp": [5, 12, 19, 21, 32, 33], "symmetr": [5, 15, 19, 27, 28, 29, 32, 33, 34], "block_siz": [5, 7, 8, 9, 10, 12, 13, 14, 19, 21, 23, 25, 26, 37], "int16": [5, 8], "_": 5, "int_data": [5, 7], "from_plain": 5, "under": [5, 36], "understand": 5, "layout_typ": 5, "layouttyp": 5, "entri": 5, "behavior": 5, "torch_funct": 5, "torch_dispatch": 5, "whenev": 5, "detach": 5, "reshap": 5, "mm": [5, 36], "addmm": 5, "default": [5, 7, 18, 19, 23, 25, 27, 28, 29, 31, 36, 37, 40, 41, 43], "l361": 5, "l389": 5, "helper": 5, "overwrit": 5, "callback": 5, "decor": 5, "inherit": 5, "my_dtype_tensor_cl": 5, "isinst": [5, 36], "arg": [5, 7, 8, 45], "0": [5, 7, 18, 19, 36, 37, 41, 45, 52, 53, 56, 57], "len": 5, "except": 5, "fallback": [5, 39], "pick": [5, 18], "path": [5, 36, 39], "branch": 5, "notimplementederror": 5, "func": 5, "return_and_correct_alias": 5, "wrapper": 5, "ensur": 5, "properli": [5, 52], "alias": 5, "everi": [5, 44], "correct": [5, 7], "aotautograd": 5, "_apply_fn_to_data": 5, "my_dtyp": 5, "depend": [5, 7, 18, 52], "commonli": 5, "overwritten": 5, "find": [5, 8], "gradual": 5, "coverag": 5, "expect": [5, 35], "m": [5, 36, 38, 52], "super": [5, 52], "10": [5, 15, 37], "x": [5, 36, 43, 52, 57], "overrid": 5, "torchfunctionmod": 5, "torchfunctionloggingmod": 5, "print": [5, 45, 52, 57], "torch_func": 5, "str": [5, 22, 36, 41, 42, 45], "example_input": [5, 18, 52], "built": 5, "_c": 5, "tensorbas": 5, "torchdispatchmod": 5, "torchdispatchloggingmod": 5, "aten_func": 5, "polish": 5, "log": [5, 18], "alband": 5, "subclass_zoo": 5, "logging_mod": 5, "parallel": 5, "discov": 5, "miss": 5, "regist": [5, 44], "own": [5, 36], "autotun": 5, "cpu": [5, 7, 52], "cuda": [5, 7, 22, 36, 52], "mp": 5, "csrc": 5, "access": 5, "my_custom_op": 5, "devic": [5, 7, 22, 36, 39, 52], "target": [5, 19, 27, 28, 29, 31, 45], "register_aqt_quantized_linear_dispatch": 5, "sometim": 5, "yield": 5, "full": [5, 57], "wrap": [5, 18], "my": 5, "to_my_dtyp": 5, "filter": [5, 18], "unwrap_tensor_subclass": 5, "m_unwrap": 5, "fullgraph": 5, "true": [5, 7, 12, 18, 19, 21, 22, 36, 40, 52], "remov": [5, 45], "unnecessari": 5, "graph": 5, "break": 5, "torch_log": 5, "output_cod": 5, "script": [5, 57], "inductor": [5, 18, 36], "mode": [5, 18, 31], "huggingfac": 5, "save_pretrain": 5, "push_to_hub": 5, "from_pretrain": 5, "co": 5, "en": [5, 18], "diffus": 5, "sayakpaul": 5, "serialization_and_load": 5, "md": 5, "put": 5, "developer_api_guid": 5, "folder": 5, "executorch": [5, 32, 36], "torchchat": 5, "qat": [5, 25, 26], "fp4": 5, "mostli": [5, 21], "int3": 5, "exact": 5, "affine_quantized_tensor": [5, 52], "quant_api": [5, 36, 52], "slight": 5, "quant_primit": [5, 7], "mayb": 5, "marlin": 5, "aqt": 5, "621": 5, "split": 5, "suit": 5, "system": 5, "dtensor": 5, "copi": [5, 7, 45, 52], "past": 5, "adapt": 5, "singl": [5, 18, 21, 27], "intens": 5, "memori": [5, 7, 26], "dimens": [5, 7, 19, 23, 25, 35, 37, 43], "file": [5, 53, 56], "benchmark_aq": 5, "quick": 5, "print_op_and_shap": 5, "k": [5, 39, 52], "n": [5, 52], "benchmark_your_kernel": 5, "either": [5, 7, 19, 23, 25, 27, 37, 45], "probabl": 5, "keep": [5, 45], "llama": 5, "llama2": 5, "llama3": 5, "sam": 5, "our": [5, 8], "bound": 5, "profil": 5, "profile_path": 5, "chrome": 5, "know": [5, 18], "torchao": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 52], "aqttensorimpl": 7, "tupl": [7, 8, 9, 10, 12, 13, 19, 21, 22, 23, 25, 26, 27, 28, 37, 45], "int": [7, 8, 9, 10, 12, 13, 14, 19, 20, 21, 22, 23, 24, 25, 26, 30, 36, 37, 38, 45], "union": [7, 19, 23, 25, 26, 27, 28, 36, 37], "zero_point_domain": [7, 12, 13, 19, 21, 23, 25, 26, 31, 36, 37], "zeropointdomain": [7, 12, 13, 19, 21, 23, 25, 26, 31, 37], "sourc": [7, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 55, 57], "tensor": [7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 35, 36, 37, 38, 39, 42, 45, 52, 57], "subclass": [7, 18, 36, 44, 52], "quantized_tensor": 7, "float_tensor": 7, "dure": [7, 18, 19, 23, 25, 37, 41], "primit": 7, "op": [7, 18, 19, 25, 26, 31, 36], "qand": 7, "dequantize_affin": [7, 25, 26, 31], "regardless": 7, "intern": 7, "orient": 7, "field": 7, "serv": 7, "gener": [7, 25, 26, 55, 57], "plain": 7, "oper": [7, 21], "kernel": [7, 30, 31, 36], "element": [7, 18, 19, 23, 25, 37], "share": [7, 19, 23, 25, 37], "qparam": [7, 19, 23, 25, 37], "us": [7, 8, 15, 18, 19, 21, 23, 25, 27, 28, 31, 32, 36, 37, 43, 45, 48, 52], "torch": [7, 8, 18, 19, 22, 23, 24, 25, 27, 28, 29, 31, 35, 36, 37, 39, 40, 41, 43, 52, 57], "high": [7, 38], "minimum": [7, 18, 19, 23, 25, 37], "specifi": [7, 25, 36, 37, 43, 45], "deriv": [7, 21, 25, 37], "maximum": [7, 19, 23, 25, 37, 40], "domain": [7, 17, 19, 23, 25, 31, 37], "integ": [7, 15, 17, 19, 23, 25, 31, 35, 37, 39], "zero": [7, 19, 23, 25, 31, 37, 45], "ad": [7, 19, 23, 25, 37, 45], "subtract": [7, 8, 19, 23, 25, 37], "unquant": [7, 19, 23, 25, 37], "float32": [7, 23, 24, 25, 37, 38, 52], "given": [7, 19], "perform": [7, 18, 35, 39, 40, 44], "desir": [7, 18, 25], "non_block": 7, "memory_format": 7, "preserve_format": 7, "tri": 7, "asynchron": 7, "respect": 7, "host": 7, "possibl": 7, "pin": 7, "set": [7, 18, 21, 36, 40, 45], "new": [7, 36], "even": 7, "match": [7, 23, 35], "other": [7, 45, 52, 57], "exampl": [7, 15, 18, 19, 36, 45, 52, 53, 55, 56, 57], "randn": [7, 52], "float64": 7, "5044": 7, "0005": 7, "3310": 7, "0584": 7, "cuda0": 7, "tensor_meta": 8, "subclasstensorarg": 8, "n_block": 8, "scaler_block_s": [8, 14], "quantized_scal": 8, "quantization_factor": 8, "scaler_mean": 8, "quantized_data": 8, "nf4": 8, "weight": [8, 18, 27, 28, 29, 31, 32, 33, 34, 36, 43, 45, 48, 52], "qlora": 8, "static": [8, 21, 28], "convert_to_norm_float_weight": 8, "normal": [8, 18], "dequantize_scal": 8, "doubl": 8, "scaler": 8, "per_scaler_block": 8, "factor": [8, 35, 41], "inpt_weight": 8, "n_scaler_block": 8, "block": [8, 45], "double_quantize_scal": 8, "achiev": 8, "absmax": 8, "posit": 8, "again": 8, "per_block": 8, "get_original_weight": 8, "quantize_tensor_nearest": 8, "float16": [8, 22, 25, 37], "nearest": 8, "round": [8, 15, 19], "layout": [9, 10, 11, 12, 13, 31, 32, 33], "scale_dtyp": [9, 12, 19, 21], "ep": [12, 19, 21], "zero_point_dtyp": [12, 19, 21, 36], "preserve_zero": [12, 19, 21, 31, 36], "bool": [12, 18, 19, 21, 22, 36, 40], "plainlayout": [12, 13, 32, 33], "use_hqq": [12, 31, 43], "64": [14, 22, 31, 43, 52], "256": [14, 31], "name": [15, 16, 17, 36, 41, 45], "modul": [15, 16, 17, 18, 36, 40, 41, 44, 45, 52], "qualnam": [15, 16, 17], "boundari": [15, 16, 17], "number": [15, 18, 38, 43, 45], "rang": 15, "5": [15, 41, 45, 57], "7": [15, 19], "int4": [15, 32, 36, 52], "symmetric_no_clipping_err": 15, "smin": 15, "smax": 15, "min_val_neg": 15, "max_val_po": 15, "By": 15, "individu": 15, "less": [15, 19], "error": [15, 18], "neg": 15, "placehold": 16, "yet": [16, 32], "enum": 17, "indic": [17, 19], "whether": [17, 18, 19, 31, 36, 43], "quantized_v": 17, "float_val": 17, "mid_point": 17, "qtensor_class_list": 18, "aqdefaultlinearweight": 18, "aqint8weightonlyquantizedlinearweight": 18, "aqint8weightonlyquantizedlinearweight2": 18, "aqint8dynamicallyquantizedlinearweight": 18, "filter_fn": [18, 36], "interpol": 18, "85": 18, "manual": [18, 36], "set_inductor_config": [18, 36], "supress_autoquant_error": 18, "min_sqnr": 18, "aq_kwarg": 18, "autoquant": 18, "identifi": 18, "fastest": 18, "layer": [18, 27, 29, 31, 33, 34, 40, 41, 43, 45, 46], "over": 18, "potenti": 18, "qtensor": 18, "search": 18, "whose": 18, "exchang": 18, "autoquantizablelinearweight": 18, "calibr": [18, 21], "activ": [18, 27, 28, 32, 33, 40, 45, 48], "seen": 18, "benchmark": [18, 40], "member": 18, "highli": 18, "function": [18, 22, 36, 44, 45, 46, 52], "complet": 18, "simpli": 18, "had": 18, "compil": [18, 36, 39], "case": [18, 39], "onc": 18, "proce": 18, "finalize_autoqu": 18, "been": 18, "fulli": [18, 36, 41], "unless": 18, "default_autoquant_class_list": 18, "callabl": [18, 22, 36, 42], "contain": [18, 40, 41], "stop": 18, "sever": 18, "automat": [18, 36, 57], "config": [18, 36, 45], "suppress": 18, "accept": 18, "signal": 18, "nois": 18, "ration": 18, "wikipedia": 18, "wiki": 18, "noise_ratio": 18, "v": 18, "impact": 18, "caus": 18, "too": 18, "larg": 18, "numer": 18, "resaon": 18, "40": 18, "adjust": 18, "addit": [18, 26], "keyword": 18, "usag": 18, "example_input1": 18, "example_input2": 18, "determin": [19, 25], "optioanl": 19, "flag": 19, "exactli": [19, 31], "pad": 19, "convolut": 19, "doesn": 19, "itself": 19, "loss": 19, "won": 19, "gurante": 19, "don": [19, 45], "clamp": 19, "request": [19, 23, 37], "ebit": [20, 24, 30, 38], "mbit": [20, 24, 30, 38], "observ": [21, 44], "obtain": 21, "param": [21, 26, 45], "nbit": 22, "group_siz": [22, 31, 32, 34, 36, 43], "axi": [22, 37], "compute_dtyp": 22, "verbos": 22, "raw_output": 22, "optimize_weight": 22, "optimize_weights_proximal_legaci": 22, "input_dtyp": 23, "output_dtyp": [23, 24, 37], "quant_dtyp": [25, 26], "fake": [25, 26], "awar": [25, 26, 45], "train": [25, 26, 48], "equival": [25, 26, 41], "cast": [25, 26], "valid": 25, "fake_quantize_affin": 26, "consum": 26, "outlier": 26, "mask": [26, 45], "intermedi": 26, "activation_dtyp": [27, 28], "weight_dtyp": [27, 28, 29], "pertensor": [27, 28], "perrow": [27, 28], "mm_config": [27, 28], "float8mmconfig": [27, 28], "dynam": [27, 32, 33], "current": [27, 32, 36, 41, 45], "onli": [27, 29, 31, 32, 34, 36, 43, 52], "support": [27, 32, 52], "matrix": [27, 28, 35, 39, 45], "fast": [27, 28], "accumul": [27, 28], "float8_e4m": 28, "channel": [29, 33, 34, 44], "sub": [30, 43], "byte": [30, 43], "defin": [30, 44, 45], "expon": [30, 38], "bit": [30, 38, 43], "mantissa": [30, 38], "fp6_e3_m2": 30, "fp6_e2_m3": 30, "fp6": 30, "llm": 30, "paper": [30, 57], "arxiv": [30, 45], "ab": [30, 45], "2401": 30, "14112": 30, "repo": 30, "usyd": 30, "fsalab": 30, "fp6_llm": 30, "renam": 30, "fpxtensorcoreaqttensorimpl": 30, "experiment": 30, "merg": 30, "to_affine_quantized_floatx": 30, "128": 31, "inner_k_til": 31, "int4mm": 31, "_weight_int4pack_mm_for_cpu": 31, "algorithm": [31, 43], "tradit": 31, "code": [31, 55, 57], "chosen": 31, "control": [31, 32, 43, 45], "smaller": [31, 32, 43, 52], "grain": [31, 32, 43], "choic": 31, "32": [31, 32, 36, 52], "act_mapping_typ": [32, 33], "token": [32, 33], "produc": 32, "backend": 32, "did": 32, "flow": 32, "marlinqqqlayout": 32, "b": 35, "scales1": 35, "multipli": [35, 39], "row": 35, "rais": [35, 39], "assertionerror": [35, 39], "inplac": [36, 45], "qualifi": [36, 41], "speed": 36, "predefin": 36, "execut": [36, 53, 56], "customiz": 36, "int8_dynamic_activation_int4_weight": 36, "int8_dynamic_activation_int8_weight": 36, "int8_weight_onli": 36, "sequenti": 36, "1024": [36, 52], "write": 36, "add": [36, 57], "constructor": 36, "groupwis": 36, "groupsiz": [36, 37], "apply_weight_qu": 36, "lambda": 36, "15": 36, "1e": 36, "apply_weight_quant_to_linear": 36, "block0": 36, "submodul": 36, "fqn": [36, 45], "per_tensor": 37, "per_axi": 37, "per_group": 37, "low": 38, "00seeemm": 38, "fp6_e3m2": 38, "sign": 38, "mat2": 39, "safe": 39, "cubla": 39, "i": 39, "j": 39, "debug_skip_calibr": 40, "smoothquant": [40, 41], "smoothfakedynamicallyquantizedlinear": [40, 41], "debug": 40, "skip_fqn_list": 41, "cur_fqn": 41, "alpha": 41, "replac": 41, "skip": [41, 45], "quant_kwarg": 42, "dict": [42, 45], "pack_dim": 43, "custom": [44, 48], "l2": 44, "norm": [44, 45], "buffer": 44, "x_orig": 44, "overridden": 44, "although": 44, "recip": 44, "within": 44, "afterward": 44, "former": 44, "care": [44, 52], "while": [44, 45], "latter": 44, "silent": 44, "sparsity_level": 45, "semi_structured_block_s": 45, "wanda": 45, "sparsifi": [45, 48, 52], "prune": 45, "propos": 45, "2306": 45, "11695": 45, "product": 45, "magnitud": 45, "variabl": 45, "level": 45, "parametr": 45, "preserv": 45, "deepcopi": 45, "squash_mask": 45, "params_to_keep": 45, "params_to_keep_per_lay": 45, "squash": 45, "sparse_param": 45, "attach": 45, "kei": [45, 57], "save": [45, 52], "string": 45, "xdoctest": 45, "local": 45, "undefin": 45, "hasattr": 45, "submodule1": 45, "linear1": [45, 52], "foo": 45, "bar": 45, "submodule2": 45, "linear42": 45, "baz": 45, "42": 45, "24": 45, "update_mask": 45, "tensor_nam": 45, "retriev": 45, "act_per_input": 45, "Then": 45, "metric": 45, "across": 45, "whole": 45, "librari": [48, 52], "gradient": 48, "nativ": 48, "readm": 48, "overal": 48, "recent": 48, "highlight": [48, 57], "updat": [48, 52], "develop": 48, "serial": 48, "work": 52, "tempfil": 52, "get_model_size_in_byt": 52, "toylinearmodel": 52, "linear2": 52, "batch_siz": 52, "in_featur": 52, "eval": 52, "mb": [52, 53, 56], "ref": 52, "namedtemporaryfil": 52, "state_dict": 52, "seek": 52, "load": 52, "meta": 52, "m_load": 52, "load_state_dict": 52, "assign": 52, "re": 52, "assert": 52, "equal": 52, "structur": 52, "float_weight1": 52, "float_weight2": 52, "quantized_weight1": 52, "quantized_weight2": 52, "go": [52, 57], "techinqu": 52, "implement": 52, "reduct": 52, "around": 52, "4x": 52, "0625": 52, "reason": 52, "avoid": 52, "verifi": 52, "00": [53, 56], "004": [53, 56, 57], "total": [53, 56, 57], "galleri": [53, 55, 57], "mem": [53, 56], "templat": [53, 55, 56], "tutorials_sourc": 53, "template_tutori": [53, 56, 57], "download": [55, 57], "tutorials_python": 55, "zip": [55, 57], "jupyt": [55, 57], "notebook": [55, 57], "tutorials_jupyt": 55, "sphinx": [55, 57], "author": 57, "firstnam": 57, "lastnam": 57, "item": 57, "prerequisit": 57, "v2": 57, "gpu": 57, "why": 57, "topic": 57, "link": 57, "research": 57, "rand": 57, "1577": 57, "0302": 57, "1548": 57, "1433": 57, "7988": 57, "4566": 57, "8849": 57, "2766": 57, "0457": 57, "5098": 57, "1551": 57, "8473": 57, "0043": 57, "8811": 57, "1623": 57, "practic": 57, "test": 57, "knowledg": 57, "nlp": 57, "scratch": 57, "summar": 57, "takeawai": 57, "link1": 57, "link2": 57, "time": 57, "minut": 57, "ipynb": 57}, "objects": {"torchao.dtypes": [[7, 0, 1, "", "AffineQuantizedTensor"], [8, 0, 1, "", "NF4Tensor"], [9, 2, 1, "", "to_affine_quantized_floatx"], [10, 2, 1, "", "to_affine_quantized_floatx_static"], [11, 2, 1, "", "to_affine_quantized_fpx"], [12, 2, 1, "", "to_affine_quantized_intx"], [13, 2, 1, "", "to_affine_quantized_intx_static"], [14, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[7, 1, 1, "", "dequantize"], [7, 1, 1, "", "to"]], "torchao.dtypes.NF4Tensor": [[8, 1, 1, "", "convert_to_norm_float_weight"], [8, 1, 1, "", "dequantize"], [8, 1, 1, "", "dequantize_scalers"], [8, 1, 1, "", "double_quantize_scalers"], [8, 1, 1, "", "get_original_weight"], [8, 1, 1, "", "quantize_tensor_nearest"]], "torchao.quantization": [[15, 0, 1, "", "MappingType"], [16, 0, 1, "", "TorchAODType"], [17, 0, 1, "", "ZeroPointDomain"], [18, 2, 1, "", "autoquant"], [19, 2, 1, "", "choose_qparams_affine"], [20, 2, 1, "", "choose_qparams_affine_floatx"], [21, 2, 1, "", "choose_qparams_affine_with_min_max"], [22, 2, 1, "", "choose_qparams_and_quantize_affine_hqq"], [23, 2, 1, "", "dequantize_affine"], [24, 2, 1, "", "dequantize_affine_floatx"], [25, 2, 1, "", "fake_quantize_affine"], [26, 2, 1, "", "fake_quantize_affine_cachemask"], [27, 2, 1, "", "float8_dynamic_activation_float8_weight"], [28, 2, 1, "", "float8_static_activation_float8_weight"], [29, 2, 1, "", "float8_weight_only"], [30, 2, 1, "", "fpx_weight_only"], [31, 2, 1, "", "int4_weight_only"], [32, 2, 1, "", "int8_dynamic_activation_int4_weight"], [33, 2, 1, "", "int8_dynamic_activation_int8_weight"], [34, 2, 1, "", "int8_weight_only"], [35, 2, 1, "", "int_scaled_matmul"], [36, 2, 1, "", "quantize_"], [37, 2, 1, "", "quantize_affine"], [38, 2, 1, "", "quantize_affine_floatx"], [39, 2, 1, "", "safe_int_mm"], [40, 2, 1, "", "smooth_fq_linear_to_inference"], [41, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [42, 2, 1, "", "to_linear_activation_quantized"], [43, 2, 1, "", "uintx_weight_only"]], "torchao": [[4, 3, 0, "-", "sparsity"]], "torchao.sparsity": [[44, 0, 1, "", "PerChannelNormObserver"], [45, 0, 1, "", "WandaSparsifier"], [46, 2, 1, "", "apply_fake_sparsity"]], "torchao.sparsity.PerChannelNormObserver": [[44, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[45, 1, 1, "", "prepare"], [45, 1, 1, "", "squash_mask"], [45, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 48], "dtype": [0, 5, 6], "api": [1, 48], "refer": [1, 48], "python": 1, "kernel": [2, 5, 50], "quantiz": [3, 5, 36, 51], "sparsiti": [4, 54], "contributor": [5, 48], "guid": [5, 48], "object": 5, "stack": 5, "overview": [5, 49, 57], "basic": 5, "current": 5, "support": 5, "ad": 5, "placehold": 5, "pytorch": 5, "implement": 5, "tensor": 5, "oper": 5, "subclass": 5, "integr": 5, "nativ": 5, "factori": 5, "function": 5, "primit": 5, "op": 5, "effici": 5, "deriv": 5, "layout": 5, "tensorimpl": 5, "algorithm": 5, "flow": [5, 52], "weight": 5, "onli": 5, "dynam": 5, "activ": 5, "static": 5, "insert": 5, "observ": 5, "how": 5, "defin": 5, "modul": 5, "add": 5, "model": [5, 52], "calibr": 5, "other": 5, "train": 5, "awar": 5, "low": 5, "bit": 5, "optim": [5, 52], "case": 5, "studi": 5, "int4": 5, "work": 5, "high": 5, "level": 5, "summari": 5, "dure": 5, "execut": 5, "save": 5, "load": 5, "develop": 5, "prerequisit": 5, "why": 5, "exampl": 5, "code": 5, "new": 5, "structur": 5, "custom": 5, "triton": 5, "hand": 5, "written": 5, "dispatch": 5, "us": 5, "torch": 5, "compil": 5, "perform": [5, 50], "serial": [5, 52], "featur": 5, "gener": 5, "extend": 5, "compos": 5, "test": 5, "microbenchmark": 5, "benchmark": 5, "eval": 5, "affinequantizedtensor": 7, "nf4tensor": 8, "to_affine_quantized_floatx": 9, "to_affine_quantized_floatx_stat": 10, "to_affine_quantized_fpx": 11, "to_affine_quantized_intx": 12, "to_affine_quantized_intx_stat": 13, "to_nf4": 14, "mappingtyp": 15, "torchaodtyp": 16, "zeropointdomain": 17, "autoqu": 18, "choose_qparams_affin": 19, "choose_qparams_affine_floatx": 20, "choose_qparams_affine_with_min_max": 21, "choose_qparams_and_quantize_affine_hqq": 22, "dequantize_affin": 23, "dequantize_affine_floatx": 24, "fake_quantize_affin": 25, "fake_quantize_affine_cachemask": 26, "float8_dynamic_activation_float8_weight": 27, "float8_static_activation_float8_weight": 28, "float8_weight_onli": 29, "fpx_weight_onli": 30, "int4_weight_onli": 31, "int8_dynamic_activation_int4_weight": 32, "int8_dynamic_activation_int8_weight": 33, "int8_weight_onli": 34, "int_scaled_matmul": 35, "quantize_affin": 37, "quantize_affine_floatx": 38, "safe_int_mm": 39, "smooth_fq_linear_to_infer": 40, "swap_linear_with_smooth_fq_linear": 41, "to_linear_activation_quant": 42, "uintx_weight_onli": 43, "perchannelnormobserv": 44, "wandasparsifi": 45, "apply_fake_spars": 46, "get": 47, "start": 47, "welcom": 48, "document": 48, "tutori": [48, 57], "deseri": 52, "what": 52, "happen": 52, "when": 52, "an": 52, "comput": [53, 56], "time": [53, 56], "templat": 57, "step": 57, "option": 57, "addit": 57, "exercis": 57, "conclus": 57, "further": 57, "read": 57}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})