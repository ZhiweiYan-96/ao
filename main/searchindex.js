Search.setIndex({"docnames": ["api_ref_dtypes", "api_ref_intro", "api_ref_kernel", "api_ref_quantization", "api_ref_sparsity", "contributor_guide", "dtypes", "generated/torchao.dtypes.AffineQuantizedTensor", "generated/torchao.dtypes.BlockSparseLayout", "generated/torchao.dtypes.CutlassInt4PackedLayout", "generated/torchao.dtypes.Float8Layout", "generated/torchao.dtypes.Int4CPULayout", "generated/torchao.dtypes.Layout", "generated/torchao.dtypes.MarlinQQQLayout", "generated/torchao.dtypes.MarlinQQQTensor", "generated/torchao.dtypes.MarlinSparseLayout", "generated/torchao.dtypes.NF4Tensor", "generated/torchao.dtypes.PlainLayout", "generated/torchao.dtypes.SemiSparseLayout", "generated/torchao.dtypes.TensorCoreTiledLayout", "generated/torchao.dtypes.UintxLayout", "generated/torchao.dtypes.to_affine_quantized_floatx", "generated/torchao.dtypes.to_affine_quantized_floatx_static", "generated/torchao.dtypes.to_affine_quantized_fpx", "generated/torchao.dtypes.to_affine_quantized_intx", "generated/torchao.dtypes.to_affine_quantized_intx_static", "generated/torchao.dtypes.to_marlinqqq_quantized_intx", "generated/torchao.dtypes.to_nf4", "generated/torchao.quantization.MappingType", "generated/torchao.quantization.TorchAODType", "generated/torchao.quantization.ZeroPointDomain", "generated/torchao.quantization.autoquant", "generated/torchao.quantization.choose_qparams_affine", "generated/torchao.quantization.choose_qparams_affine_floatx", "generated/torchao.quantization.choose_qparams_affine_with_min_max", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq", "generated/torchao.quantization.dequantize_affine", "generated/torchao.quantization.dequantize_affine_floatx", "generated/torchao.quantization.fake_quantize_affine", "generated/torchao.quantization.fake_quantize_affine_cachemask", "generated/torchao.quantization.float8_dynamic_activation_float8_weight", "generated/torchao.quantization.float8_static_activation_float8_weight", "generated/torchao.quantization.float8_weight_only", "generated/torchao.quantization.fpx_weight_only", "generated/torchao.quantization.int4_weight_only", "generated/torchao.quantization.int8_dynamic_activation_int4_weight", "generated/torchao.quantization.int8_dynamic_activation_int8_weight", "generated/torchao.quantization.int8_weight_only", "generated/torchao.quantization.int_scaled_matmul", "generated/torchao.quantization.quantize_", "generated/torchao.quantization.quantize_affine", "generated/torchao.quantization.quantize_affine_floatx", "generated/torchao.quantization.safe_int_mm", "generated/torchao.quantization.smooth_fq_linear_to_inference", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear", "generated/torchao.quantization.to_linear_activation_quantized", "generated/torchao.quantization.uintx_weight_only", "generated/torchao.sparsity.PerChannelNormObserver", "generated/torchao.sparsity.WandaSparsifier", "generated/torchao.sparsity.apply_fake_sparsity", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight", "generated/torchao.sparsity.semi_sparse_weight", "generated/torchao.sparsity.sparsify_", "index", "performant_kernels", "quantization", "quick_start", "serialization", "sg_execution_times", "sparsity", "subclass_advanced", "subclass_basic", "tutorials/index", "tutorials/sg_execution_times", "tutorials/template_tutorial"], "filenames": ["api_ref_dtypes.rst", "api_ref_intro.rst", "api_ref_kernel.rst", "api_ref_quantization.rst", "api_ref_sparsity.rst", "contributor_guide.rst", "dtypes.rst", "generated/torchao.dtypes.AffineQuantizedTensor.rst", "generated/torchao.dtypes.BlockSparseLayout.rst", "generated/torchao.dtypes.CutlassInt4PackedLayout.rst", "generated/torchao.dtypes.Float8Layout.rst", "generated/torchao.dtypes.Int4CPULayout.rst", "generated/torchao.dtypes.Layout.rst", "generated/torchao.dtypes.MarlinQQQLayout.rst", "generated/torchao.dtypes.MarlinQQQTensor.rst", "generated/torchao.dtypes.MarlinSparseLayout.rst", "generated/torchao.dtypes.NF4Tensor.rst", "generated/torchao.dtypes.PlainLayout.rst", "generated/torchao.dtypes.SemiSparseLayout.rst", "generated/torchao.dtypes.TensorCoreTiledLayout.rst", "generated/torchao.dtypes.UintxLayout.rst", "generated/torchao.dtypes.to_affine_quantized_floatx.rst", "generated/torchao.dtypes.to_affine_quantized_floatx_static.rst", "generated/torchao.dtypes.to_affine_quantized_fpx.rst", "generated/torchao.dtypes.to_affine_quantized_intx.rst", "generated/torchao.dtypes.to_affine_quantized_intx_static.rst", "generated/torchao.dtypes.to_marlinqqq_quantized_intx.rst", "generated/torchao.dtypes.to_nf4.rst", "generated/torchao.quantization.MappingType.rst", "generated/torchao.quantization.TorchAODType.rst", "generated/torchao.quantization.ZeroPointDomain.rst", "generated/torchao.quantization.autoquant.rst", "generated/torchao.quantization.choose_qparams_affine.rst", "generated/torchao.quantization.choose_qparams_affine_floatx.rst", "generated/torchao.quantization.choose_qparams_affine_with_min_max.rst", "generated/torchao.quantization.choose_qparams_and_quantize_affine_hqq.rst", "generated/torchao.quantization.dequantize_affine.rst", "generated/torchao.quantization.dequantize_affine_floatx.rst", "generated/torchao.quantization.fake_quantize_affine.rst", "generated/torchao.quantization.fake_quantize_affine_cachemask.rst", "generated/torchao.quantization.float8_dynamic_activation_float8_weight.rst", "generated/torchao.quantization.float8_static_activation_float8_weight.rst", "generated/torchao.quantization.float8_weight_only.rst", "generated/torchao.quantization.fpx_weight_only.rst", "generated/torchao.quantization.int4_weight_only.rst", "generated/torchao.quantization.int8_dynamic_activation_int4_weight.rst", "generated/torchao.quantization.int8_dynamic_activation_int8_weight.rst", "generated/torchao.quantization.int8_weight_only.rst", "generated/torchao.quantization.int_scaled_matmul.rst", "generated/torchao.quantization.quantize_.rst", "generated/torchao.quantization.quantize_affine.rst", "generated/torchao.quantization.quantize_affine_floatx.rst", "generated/torchao.quantization.safe_int_mm.rst", "generated/torchao.quantization.smooth_fq_linear_to_inference.rst", "generated/torchao.quantization.swap_linear_with_smooth_fq_linear.rst", "generated/torchao.quantization.to_linear_activation_quantized.rst", "generated/torchao.quantization.uintx_weight_only.rst", "generated/torchao.sparsity.PerChannelNormObserver.rst", "generated/torchao.sparsity.WandaSparsifier.rst", "generated/torchao.sparsity.apply_fake_sparsity.rst", "generated/torchao.sparsity.int8_dynamic_activation_int8_semi_sparse_weight.rst", "generated/torchao.sparsity.semi_sparse_weight.rst", "generated/torchao.sparsity.sparsify_.rst", "index.rst", "performant_kernels.rst", "quantization.rst", "quick_start.rst", "serialization.rst", "sg_execution_times.rst", "sparsity.rst", "subclass_advanced.rst", "subclass_basic.rst", "tutorials/index.rst", "tutorials/sg_execution_times.rst", "tutorials/template_tutorial.rst"], "titles": ["torchao.dtypes", "<code class=\"docutils literal notranslate\"><span class=\"pre\">torchao</span></code> API Reference", "torchao.kernel", "torchao.quantization", "torchao.sparsity", "Contributor Guide", "Dtypes", "AffineQuantizedTensor", "BlockSparseLayout", "CutlassInt4PackedLayout", "Float8Layout", "Int4CPULayout", "Layout", "MarlinQQQLayout", "MarlinQQQTensor", "MarlinSparseLayout", "NF4Tensor", "PlainLayout", "SemiSparseLayout", "TensorCoreTiledLayout", "UintxLayout", "to_affine_quantized_floatx", "to_affine_quantized_floatx_static", "to_affine_quantized_fpx", "to_affine_quantized_intx", "to_affine_quantized_intx_static", "to_marlinqqq_quantized_intx", "to_nf4", "MappingType", "TorchAODType", "ZeroPointDomain", "autoquant", "choose_qparams_affine", "choose_qparams_affine_floatx", "choose_qparams_affine_with_min_max", "choose_qparams_and_quantize_affine_hqq", "dequantize_affine", "dequantize_affine_floatx", "fake_quantize_affine", "fake_quantize_affine_cachemask", "float8_dynamic_activation_float8_weight", "float8_static_activation_float8_weight", "float8_weight_only", "fpx_weight_only", "int4_weight_only", "int8_dynamic_activation_int4_weight", "int8_dynamic_activation_int8_weight", "int8_weight_only", "int_scaled_matmul", "quantize", "quantize_affine", "quantize_affine_floatx", "safe_int_mm", "smooth_fq_linear_to_inference", "swap_linear_with_smooth_fq_linear", "to_linear_activation_quantized", "uintx_weight_only", "PerChannelNormObserver", "WandaSparsifier", "apply_fake_sparsity", "int8_dynamic_activation_int8_semi_sparse_weight", "semi_sparse_weight", "sparsify", "Welcome to the torchao Documentation", "Performant Kernels", "Quantization Overview", "Quick Start Guide", "Serialization", "Computation times", "Sparsity Overview", "Writing Your Own Quantized Tensor (advanced)", "Writing Your Own Quantized Tensor", "&lt;no title&gt;", "Computation times", "Template Tutorial"], "terms": {"thi": [1, 5, 7, 15, 16, 17, 18, 20, 28, 31, 32, 34, 36, 38, 39, 43, 44, 45, 49, 50, 57, 58, 59, 62, 66, 67, 69, 71, 74], "section": [1, 5, 69], "introduc": 1, "dive": 1, "detail": [1, 5, 31, 43, 66, 69, 71], "how": [1, 7, 12, 20, 28, 32, 44, 50, 66, 67, 69, 71], "integr": [1, 67, 69, 71], "pytorch": [1, 7, 11, 14, 29, 63, 66, 69, 71, 74], "optim": [1, 15, 31, 35, 49, 63, 69, 71], "your": [1, 5, 49, 63, 66, 69], "machin": 1, "learn": [1, 44, 66, 69, 74], "model": [1, 31, 45, 49, 53, 54, 58, 59, 62, 66, 69, 71], "dtype": [1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 49, 50, 56, 62, 63, 66, 67, 71], "quantiz": [1, 7, 9, 10, 11, 13, 14, 15, 16, 18, 19, 21, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 60, 62, 63, 67, 69], "sparsiti": [1, 5, 15, 18, 57, 58, 59, 60, 61, 62, 63, 67], "tba": [2, 6, 64], "In": [5, 66, 69, 71], "doc": [5, 71], "we": [5, 7, 16, 28, 31, 32, 34, 36, 38, 49, 50, 56, 62, 66, 67, 69], "ll": [5, 28, 32, 71], "talk": 5, "about": [5, 44, 66, 67, 69], "1": [5, 15, 20, 28, 29, 30, 31, 32, 35, 44, 49, 50, 56, 58, 66, 67, 68, 69, 71, 73, 74], "differ": [5, 12, 34, 44, 50, 52, 66, 67, 69, 71], "techniqu": [5, 67, 69, 71], "ar": [5, 7, 10, 18, 20, 31, 32, 36, 38, 40, 43, 44, 49, 50, 52, 58, 66, 67, 69], "structur": [5, 18, 61, 62, 66, 67, 69, 71], "2": [5, 7, 11, 15, 18, 28, 31, 32, 39, 44, 49, 50, 59, 60, 61, 62, 66, 69, 71, 74], "contribut": [5, 66, 69], "note": [5, 39, 58, 66, 69, 71], "heavili": 5, "focus": [5, 69], "infer": [5, 7, 53, 63, 66, 67, 69, 71], "right": [5, 69], "now": [5, 43, 45, 66, 69, 71], "plan": 5, "expand": 5, "cover": [5, 74], "futur": [5, 43], "well": [5, 12, 31, 69], "first": [5, 16, 31, 48, 58, 71], "want": [5, 49, 62, 67, 69, 71], "lai": 5, "out": [5, 18, 28, 31, 58, 66, 69, 71], "hqq": [5, 44, 56], "awq": 5, "gptq": 5, "etc": 5, "affinequantizedtensor": [5, 14, 22, 23, 25, 66, 67, 71], "codebookquantizedtensor": 5, "matmul": [5, 19, 42, 69, 71], "dequant": [5, 7, 14, 16, 36, 44, 71], "uint1": [5, 56], "uint7": [5, 56], "int1": 5, "int8": [5, 16, 45, 46, 47, 49, 60, 62, 71], "float3": 5, "float8": [5, 7, 10, 21, 22, 40, 41, 42], "ani": [5, 17, 31, 55, 58, 69, 71], "some": [5, 31, 49, 58, 69, 71], "compon": [5, 71], "from": [5, 7, 16, 17, 22, 23, 25, 32, 34, 36, 38, 43, 45, 49, 50, 62, 66, 67, 68, 69, 71, 73, 74], "abov": [5, 28, 67, 69, 71], "exampl": [5, 7, 28, 31, 32, 49, 58, 62, 67, 68, 69, 71, 72, 73, 74], "int4_weight_onli": [5, 49, 66, 67], "tinygemm": [5, 11, 44, 49, 66], "bf16": [5, 32, 66, 69], "quant": [5, 7, 14, 43], "3": [5, 28, 31, 32, 50, 66, 69, 74], "tensorcoretiledlayout": [5, 44, 66], "4": [5, 15, 18, 27, 32, 35, 59, 60, 61, 62, 66, 67, 69, 71], "uint4": [5, 44, 49, 66], "simul": [5, 59, 69], "quant_min": [5, 7, 14, 24, 25, 26, 28, 32, 34, 36, 38, 39, 50, 66, 71], "quant_max": [5, 7, 14, 24, 25, 26, 28, 32, 34, 36, 38, 39, 50, 66, 71], "also": [5, 31, 49, 66, 67, 69, 71], "overload": [5, 69], "term": [5, 69], "mean": [5, 7, 16, 28, 32, 36, 38, 50, 51, 66, 69], "make": [5, 32, 71], "sens": [5, 71], "without": [5, 32, 38, 39, 69], "extra": 5, "metadata": [5, 17, 71], "e": [5, 7, 28, 31, 32, 36, 38, 43, 49, 50, 51, 62, 67, 71], "g": [5, 7, 28, 31, 32, 36, 38, 43, 49, 50, 62, 67, 71], "when": [5, 7, 17, 32, 36, 38, 50, 69], "peopl": [5, 67], "call": [5, 7, 31, 38, 39, 49, 57, 66, 67, 69, 71], "empti": 5, "more": [5, 31, 39, 43, 44, 45, 56, 66, 69, 71], "pleas": [5, 7, 14, 43, 44, 63, 69, 71], "check": [5, 7, 14, 66, 67, 71], "dev": 5, "discuss": [5, 71], "org": [5, 31, 43, 58, 66, 69], "t": [5, 32, 58, 66, 69, 71], "new": [5, 7, 49, 71], "1833": 5, "No": [5, 67, 69], "matter": [5, 69], "what": [5, 7, 14, 31, 66, 69, 74], "do": [5, 29, 31, 32, 48, 49, 69, 71], "end": [5, 69, 71, 74], "precis": [5, 7, 21, 22, 23, 24, 25, 42, 51, 71], "repres": [5, 7, 8, 10, 12, 23, 50, 58, 67, 71], "data": [5, 7, 8, 12, 15, 20, 34, 40, 41, 42, 44, 63, 67, 69, 71], "aim": [5, 69], "uint8": [5, 36, 50], "avail": 5, "later": [5, 71], "6": [5, 11, 49, 66, 69], "float3_e2_m0": 5, "float4_e2_m1": 5, "float4_e3_m0": 5, "float5_e2_m2": 5, "float5_e3_m1": 5, "float6_e2_m3": 5, "float6_e3_m2": 5, "float8_e4m3fn": [5, 40, 41, 42], "float8_e5m2": 5, "float8_e4m3fnuz": 5, "float8_e5m2fnuz": 5, "float4": 5, "float6": 5, "thei": [5, 69, 71], "becom": 5, "popular": 5, "prototyp": 5, "consid": [5, 52, 69], "core": [5, 19, 29], "have": [5, 28, 31, 32, 44, 50, 58, 69, 71], "hardwar": [5, 69], "actual": [5, 42, 71], "two": [5, 14, 18, 40, 69, 71], "part": [5, 69, 71], "need": [5, 32, 40, 57, 58, 66, 67, 69, 71], "uint2": 5, "117208": 5, "just": [5, 28, 67, 69, 71], "so": [5, 31, 66, 67, 69, 71], "can": [5, 19, 28, 31, 40, 49, 50, 66, 67, 69, 71], "outsid": 5, "standard": [5, 20], "pack": [5, 7, 9, 19, 20, 43, 56], "format": [5, 7, 15, 16, 43, 51, 69], "As": 5, "mention": 5, "criteria": 5, "show": [5, 50, 69], "wide": 5, "adopt": 5, "For": [5, 32, 43, 66, 67, 69, 71], "fundament": [5, 69], "ones": [5, 58], "type": [5, 7, 15, 16, 20, 28, 29, 30, 31, 35, 40, 41, 42, 44, 45, 48, 50, 52, 63, 67, 69, 71], "wait": [5, 31], "until": 5, "evid": 5, "requir": [5, 17, 19, 32, 69, 71], "decid": [5, 69], "hopefulli": 5, "one": [5, 31, 34, 40, 57, 69, 71], "amen": 5, "both": [5, 40, 69, 71], "uintx": [5, 20, 56], "floatx": [5, 7, 23], "haven": 5, "enough": 5, "ont": 5, "final": [5, 31, 39, 49, 66, 69], "revisit": 5, "after": [5, 31, 67, 69], "intx": 5, "being": [5, 54, 69], "connect": 5, "creat": [5, 7, 22, 23, 25, 69, 71], "int4tensor": 5, "previou": 5, "step": [5, 17, 31, 69], "convert": [5, 7, 14, 16, 21, 24, 26, 27, 49, 51, 61, 62, 69], "between": [5, 69, 71], "preicison": 5, "mainli": 5, "follow": [5, 44, 66, 69, 71], "choose_qparam": [5, 7], "choos": [5, 69, 71], "paramet": [5, 7, 12, 15, 16, 22, 25, 28, 31, 32, 36, 38, 40, 41, 42, 44, 45, 48, 49, 50, 52, 53, 54, 56, 58, 62, 67, 69, 71], "base": [5, 12, 17, 28, 58, 66, 69, 71], "origin": [5, 7, 16, 38, 42, 50, 58, 66, 67, 69], "typic": [5, 16, 17, 32, 67], "scale": [5, 7, 12, 15, 22, 25, 28, 30, 32, 34, 36, 37, 38, 39, 41, 48, 50, 51, 53, 54, 69, 71], "zero_point": [5, 7, 12, 25, 30, 32, 34, 36, 38, 39, 44, 50, 69, 71], "affin": [5, 7, 9, 10, 11, 15, 18, 19, 24, 36, 38, 49, 50, 62], "There": [5, 71], "could": [5, 71], "variat": 5, "accommod": 5, "specif": [5, 12, 15, 17, 18, 58, 66, 67, 69], "mai": [5, 34, 67], "choose_qparams_affine_with_min_max": 5, "min": [5, 71], "max": [5, 28, 66, 71], "valu": [5, 7, 16, 28, 29, 30, 31, 32, 36, 38, 39, 44, 50, 53, 58, 69, 71], "process": [5, 12, 15, 17, 19, 20, 31, 54, 69, 74], "_weight_int4pack_mm": [5, 44], "int_matmul": 5, "take": [5, 16, 49, 57, 62, 69], "output": [5, 31, 32, 36, 38, 50, 69, 74], "an": [5, 7, 19, 24, 25, 31, 39, 58, 63, 69, 71], "int32": [5, 49, 66], "int_scaled_matmul": 5, "doe": [5, 17, 44, 69, 71], "appli": [5, 31, 40, 41, 42, 44, 45, 46, 47, 49, 56, 60, 66, 69], "result": [5, 31, 48, 51, 52, 69], "reli": [5, 69, 71], "through": [5, 34, 66, 71, 74], "get": [5, 16, 69], "speedup": [5, 44, 66, 69], "s": [5, 7, 28, 31, 32, 36, 38, 50, 51, 66, 69, 71], "correspond": [5, 32, 49, 67, 69, 71], "On": [5, 66], "top": [5, 71], "glue": 5, "everyth": 5, "togeth": 5, "build": [5, 69, 71], "construct": 5, "configur": [5, 10, 40, 41, 66], "user": [5, 31, 66, 69, 71, 74], "sinc": [5, 15, 57, 67, 69, 71], "like": [5, 12, 31, 32, 66, 67, 69, 71], "exist": [5, 29, 69, 71], "map": [5, 28, 32, 71], "low_precision_v": 5, "high_precision_v": 5, "where": [5, 18, 28, 34, 51, 56, 69], "calcul": [5, 16, 28, 32, 34, 53, 69], "procedur": 5, "veri": [5, 69], "common": [5, 69], "straightforward": 5, "try": [5, 69, 71], "higher": [5, 71], "lower": [5, 45, 69], "transform": [5, 7], "high_preicsion_v": 5, "anoth": [5, 69, 71], "especi": [5, 67, 69], "bitwidth": 5, "than": [5, 20, 69, 71], "codebook": 5, "look": [5, 7, 69], "up": [5, 16, 49, 66, 69], "tabl": [5, 50, 69], "hardcod": 5, "list": [5, 31, 36, 54, 58, 66, 71], "select": 5, "most": [5, 17, 69], "stride": [5, 7, 14, 71], "provid": [5, 12, 15, 18, 19, 31, 32, 69, 71], "multi": 5, "dimension": [5, 69], "view": [5, 71], "storag": [5, 7, 15, 69], "spars": [5, 8, 15, 18, 58, 69], "mkldnn": 5, "coo": [5, 69], "ha": [5, 7, 69, 71], "sparse_coo": [5, 69], "sparsetensorimpl": 5, "which": [5, 14, 20, 31, 66, 67, 69], "chang": [5, 49, 66, 67, 69, 71], "store": [5, 7, 15, 16, 20, 57, 69], "The": [5, 7, 8, 12, 15, 20, 31, 40, 41, 42, 43, 48, 49, 52, 53, 54, 58, 66, 67, 69, 71], "idea": [5, 69], "fit": [5, 19, 67], "nice": [5, 69], "concept": [5, 74], "why": [5, 71, 74], "reus": [5, 71], "And": [5, 16, 40, 71], "python": [5, 69, 72, 74], "modifi": [5, 49, 58, 69, 71], "c": [5, 71], "code": [5, 44, 66, 69, 71, 72, 74], "friendli": 5, "tensor_impl": [5, 7, 14], "unpack": [5, 16, 51], "relev": [5, 44, 74], "class": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 28, 29, 30, 31, 57, 58, 66, 67, 71], "conflict": 5, "properti": 5, "_layout": [5, 7, 14, 21, 22, 23, 24, 25, 26, 66], "def": [5, 49, 62, 66, 67, 71], "self": [5, 7, 66, 67, 71], "return": [5, 7, 14, 15, 16, 31, 39, 48, 49, 52, 53, 54, 62, 66, 67, 71], "abstract": 5, "represent": [5, 7, 12, 23, 32, 44, 69], "interact": [5, 12], "same": [5, 7, 32, 34, 36, 38, 39, 40, 50, 52, 62, 69, 71], "run": [5, 31, 49, 53, 57, 62, 69, 71, 74], "transpos": [5, 15, 71], "quantized_linear": 5, "semant": 5, "should": [5, 7, 32, 36, 38, 50, 57, 58, 69], "stai": [5, 66, 71], "util": [5, 66, 67, 71], "help": 5, "develop": 5, "below": [5, 69, 71, 74], "tradition": 5, "see": [5, 7, 14, 43, 66, 67, 69, 71], "come": [5, 65, 69, 70], "demonstr": [5, 66, 71], "purpos": [5, 71], "let": [5, 28, 50, 66, 69, 71], "sai": [5, 28, 50], "to_affine_quant": 5, "simplic": 5, "float": [5, 7, 14, 16, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 38, 39, 43, 44, 49, 50, 51, 54, 58, 62, 67, 71], "point": [5, 7, 14, 26, 28, 30, 32, 36, 38, 43, 44, 50, 51, 62, 66, 67, 69, 71], "target_dtyp": [5, 7, 21, 22, 24, 25, 32, 34], "all": [5, 28, 31, 34, 57, 58, 59, 66, 67, 68, 69, 71, 72], "explain": 5, "introduct": [5, 63], "found": [5, 66, 69, 71], "write": [5, 49, 63], "own": [5, 49, 63, 69], "tutori": [5, 68, 69, 71, 72, 73], "simplest": [5, 69], "form": [5, 69], "easi": 5, "linear_modul": 5, "nn": [5, 31, 49, 53, 54, 62, 66, 67, 69, 71], "to_affine_quantized_intx": [5, 49], "requires_grad": [5, 49, 71], "fals": [5, 7, 24, 31, 35, 44, 46, 49, 53, 56, 58, 66, 67, 71], "linear": [5, 15, 31, 32, 40, 42, 44, 45, 46, 47, 49, 54, 56, 59, 60, 61, 62, 66, 67, 69, 71], "befor": [5, 49, 67, 69, 71], "runtim": 5, "compar": [5, 39, 44, 58], "main": [5, 7, 14, 44, 66, 69, 71], "question": [5, 67, 69, 71], "pattern": [5, 15, 18], "to_linear_activation_quant": 5, "quantized_weight": 5, "activation_and_weight_quant": 5, "input_quant_func": [5, 55], "encount": 5, "f": [5, 67, 69, 71], "input_qunat_func": 5, "redispatch": 5, "If": [5, 7, 10, 31, 32, 40, 48, 52, 53, 58, 66, 69, 71], "swap": [5, 69], "fx": 5, "symbolic_trac": 5, "trace": 5, "you": [5, 49, 58, 66, 67, 69, 71, 74], "But": [5, 32, 71], "prefer": [5, 66, 71], "becaus": [5, 15, 67, 69, 71], "easier": 5, "deseri": 5, "directli": [5, 28, 34, 69, 71], "further": [5, 71], "prepar": [5, 31, 53, 58, 69], "otherwis": [5, 7], "d": 5, "modif": 5, "instead": [5, 34, 44, 57, 66, 69, 71], "sampl": 5, "order": [5, 31, 69, 71], "figur": [5, 69], "appropri": [5, 58], "At": [5, 69], "three": [5, 7, 31, 58, 62], "input": [5, 7, 15, 16, 18, 31, 32, 34, 36, 38, 39, 48, 49, 50, 52, 58, 62, 71], "collect": [5, 69], "statist": [5, 58, 69], "thing": [5, 67, 69, 71], "address": 5, "stat": 5, "track": [5, 34], "move": [5, 49], "averag": 5, "forward": [5, 31, 57, 66, 67, 69, 71], "calculate_qparam": 5, "affinequantizedminmaxobserv": 5, "record": [5, 31], "min_val": [5, 34, 71], "max_val": [5, 34, 71], "granular": [5, 7, 32, 36, 38, 40, 41, 44, 45, 50, 56], "interest": [5, 69, 71], "insert_observer_": 5, "api": [5, 31, 66, 69, 71], "handl": [5, 15, 18, 19, 31], "altern": [5, 71], "observedlinear": 5, "non": [5, 31, 69, 71], "dataset": 5, "complic": [5, 69], "them": [5, 31, 57], "next": 5, "quantize_": [5, 49, 62, 66, 67], "apply_tensor_subclass": [5, 49, 62], "done": [5, 71], "manner": 5, "intend": 5, "autoround": 5, "multitensor": 5, "hook": [5, 57], "sure": [5, 32], "wai": [5, 7, 31, 69, 71], "feel": [5, 69, 71], "free": [5, 71], "open": [5, 69], "issu": [5, 66, 71], "describ": [5, 67, 69, 74], "advis": 5, "todo": 5, "todai": 5, "low_bit_optim": 5, "8": [5, 19, 20, 28, 32, 44, 66], "fsdp": 5, "similar": [5, 69], "quantized_train": 5, "initi": [5, 7, 67], "enabl": 5, "progress": 5, "lot": [5, 69], "includ": [5, 71], "checkout": [5, 7, 14, 63], "trainabl": [5, 71], "To": [5, 7, 14, 31, 66, 67, 69], "here": [5, 7, 50, 67, 71], "walk": [5, 71, 74], "happen": [5, 7, 14, 31, 71], "quantize_affin": [5, 7, 38, 39, 44], "_convert_weight_to_int4pack": 5, "aten": [5, 44, 71], "start": [5, 28, 29, 30, 31, 69, 71], "asymmetr": [5, 28, 32, 44, 45, 49, 56, 66], "per": [5, 7, 32, 36, 38, 42, 44, 45, 46, 47, 50, 56, 58, 60, 66, 69], "group": [5, 44, 45, 56, 66], "tensor_core_til": [5, 44], "convers": [5, 7, 49], "second": [5, 31, 48, 74], "argument": [5, 7, 19, 31, 36, 49], "choose_qparams_affin": [5, 7, 34, 44], "tile": [5, 19], "tensorcoretiledaqttensorimpl": 5, "bia": [5, 66, 67, 71], "bfloat16": [5, 16, 38, 49, 50, 66, 67, 69], "__torch_function__": [5, 71], "weight_tensor": 5, "_quantized_linear_op": 5, "input_tensor": [5, 16], "goe": 5, "_aqt_qlinear_dispatch_t": 5, "each": [5, 16, 31, 53, 57, 69, 71], "condit": 5, "pass": [5, 31, 34, 57, 71], "explan": 5, "dispatch_condit": 5, "impl": [5, 7], "wint4": 5, "still": [5, 69], "regist": [5, 57, 71], "autotun": [5, 66], "cpu": [5, 7, 11, 67, 69], "cuda": [5, 7, 35, 49, 66, 67, 69, 71], "mp": 5, "csrc": 5, "access": 5, "my_custom_op": 5, "devic": [5, 7, 35, 49, 52, 66, 67, 71], "__torch_dispatch__": [5, 71], "target": [5, 32, 40, 41, 42, 44, 58, 69], "allow": [5, 69, 71], "register_aqt_quantized_linear_dispatch": 5, "sometim": [5, 69], "yield": [5, 69], "full": [5, 74], "wrap": [5, 31, 71], "my": [5, 69], "to_my_dtyp": 5, "mydtypetensor": 5, "from_float": [5, 71], "filter": [5, 31], "import": [5, 32, 49, 62, 66, 67, 69, 71, 74], "unwrap_tensor_subclass": [5, 66], "m_unwrap": 5, "m": [5, 49, 51, 62, 66, 67, 71], "compat": [5, 15, 66], "fullgraph": [5, 66], "true": [5, 7, 24, 31, 32, 34, 35, 49, 53, 62, 66, 67, 71], "remov": [5, 58, 69], "unnecessari": 5, "graph": 5, "break": 5, "torch_log": 5, "output_cod": 5, "script": [5, 66, 71, 74], "inductor": [5, 31, 49], "py": [5, 7, 14, 68, 73, 74], "mode": [5, 31, 44, 66], "huggingfac": 5, "save_pretrain": 5, "push_to_hub": 5, "from_pretrain": 5, "http": [5, 7, 14, 31, 43, 58, 66, 69], "co": 5, "en": [5, 31], "diffus": 5, "github": [5, 7, 14, 43, 66], "com": [5, 7, 14, 43], "sayakpaul": 5, "blob": [5, 7, 14], "serialization_and_load": 5, "md": 5, "parallel": [5, 71], "put": [5, 62], "developer_api_guid": 5, "folder": 5, "executorch": [5, 45, 49], "torchchat": 5, "qat": [5, 38, 39], "fp4": 5, "fine": [5, 44, 45, 56, 69], "mostli": [5, 34], "int3": 5, "exact": 5, "affine_quantized_tensor": [5, 67], "quant_api": [5, 49, 67], "slight": [5, 69], "quant_primit": [5, 7, 14], "mayb": 5, "marlin": [5, 13, 14, 15, 26], "aqt": 5, "621": 5, "split": 5, "suit": 5, "system": 5, "dtensor": [5, 71], "recommend": [5, 31, 49], "copi": [5, 7, 58, 66, 67, 69, 71], "past": [5, 69], "adapt": 5, "singl": [5, 31, 34, 40, 66, 69], "comput": [5, 15, 19, 42, 57, 58, 69, 71], "intens": 5, "memori": [5, 7, 39, 66, 69, 71], "dimens": [5, 7, 20, 32, 36, 38, 48, 50, 56, 71], "file": [5, 68, 71, 73], "benchmark_aq": 5, "shape": [5, 7, 14, 31, 48, 52, 66, 71], "A": [5, 7, 20, 31, 34, 39, 57, 69, 71], "quick": [5, 63], "print_op_and_shap": 5, "torch_func": 5, "built": [5, 71], "k": [5, 52, 66, 67, 71], "n": [5, 66, 67, 71], "10": [5, 28, 50], "method": [5, 12, 15, 18, 19, 31, 49, 58, 69, 71], "_c": 5, "tensorbas": 5, "arg": [5, 7, 58, 71], "0": [5, 7, 31, 32, 49, 50, 54, 58, 66, 67, 68, 69, 71, 73, 74], "size": [5, 7, 8, 14, 16, 32, 36, 38, 44, 45, 50, 56, 66, 67, 69, 71], "under": [5, 49], "benchmark_your_kernel": 5, "helper": 5, "either": [5, 7, 32, 36, 38, 40, 50, 58, 69], "probabl": 5, "keep": [5, 15, 58], "llama": 5, "llama2": 5, "llama3": 5, "sam": 5, "alreadi": [5, 7, 31, 71], "our": [5, 16, 66, 69, 71], "bound": [5, 69], "option": [5, 7, 10, 14, 21, 24, 25, 26, 31, 32, 34, 36, 38, 39, 40, 41, 49, 50, 53, 54, 55, 58, 62, 66], "understand": 5, "profil": 5, "profile_path": 5, "chrome": 5, "know": [5, 31, 71], "torchao": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 66, 67, 69, 71], "aqttensorimpl": [7, 14], "block_siz": [7, 12, 14, 16, 21, 22, 24, 25, 26, 27, 32, 34, 36, 38, 39, 50, 66], "tupl": [7, 14, 16, 21, 22, 24, 25, 26, 32, 34, 35, 36, 38, 39, 40, 41, 50, 58, 71], "int": [7, 8, 14, 16, 19, 20, 21, 22, 24, 25, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 49, 50, 51, 58, 66, 71], "union": [7, 14, 32, 36, 38, 39, 40, 41, 49, 50], "none": [7, 10, 14, 21, 24, 25, 26, 28, 29, 30, 31, 32, 34, 36, 38, 39, 40, 41, 44, 47, 49, 50, 53, 54, 55, 58, 62, 71], "zero_point_domain": [7, 14, 24, 25, 26, 32, 34, 36, 38, 39, 44, 49, 50], "zeropointdomain": [7, 14, 24, 25, 26, 32, 34, 36, 38, 39, 44, 50], "sourc": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 72, 74], "tensor": [7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 48, 49, 50, 51, 52, 55, 58, 62, 63, 66, 67, 69, 74], "subclass": [7, 14, 31, 49, 57, 62, 66, 67, 69], "quantized_tensor": 7, "float_tensor": [7, 71], "dure": [7, 14, 31, 32, 36, 38, 50, 54, 69, 71], "ao": [7, 14, 69], "primit": [7, 14, 71], "op": [7, 14, 31, 32, 38, 39, 44, 49, 69, 71], "qand": 7, "dequantize_affin": [7, 38, 39, 44], "extern": 7, "regardless": 7, "intern": [7, 19], "orient": 7, "field": 7, "serv": [7, 12, 71], "gener": [7, 38, 39, 66, 69, 71, 72, 74], "plain": 7, "int_data": [7, 71], "depend": [7, 31, 67, 69, 71], "oper": [7, 10, 12, 15, 34], "kernel": [7, 9, 11, 15, 19, 43, 44, 49, 66, 69], "element": [7, 18, 20, 31, 32, 36, 38, 50, 69], "share": [7, 32, 36, 38, 50, 69], "qparam": [7, 32, 36, 38, 50], "us": [7, 10, 11, 12, 15, 16, 17, 20, 22, 25, 28, 31, 32, 34, 36, 38, 40, 41, 44, 45, 49, 50, 56, 58, 63, 66, 67, 69, 71], "torch": [7, 15, 16, 20, 31, 32, 35, 36, 37, 38, 40, 41, 42, 44, 48, 49, 50, 52, 53, 54, 56, 62, 66, 67, 69, 71, 74], "high": [7, 21, 22, 23, 24, 25, 51, 69, 71], "minimum": [7, 31, 32, 36, 38, 50], "specifi": [7, 38, 49, 50, 56, 58, 69], "deriv": [7, 34, 38, 50], "maximum": [7, 32, 36, 38, 50, 53], "domain": [7, 30, 32, 36, 38, 44, 50], "integ": [7, 24, 25, 28, 30, 32, 36, 38, 44, 48, 50, 52], "zero": [7, 18, 32, 36, 38, 44, 50, 58, 69], "ad": [7, 32, 36, 38, 50, 58, 69, 71], "subtract": [7, 16, 32, 36, 38, 50], "unquant": [7, 32, 36, 38, 50], "default": [7, 8, 10, 17, 19, 20, 31, 32, 36, 38, 40, 41, 42, 44, 49, 50, 53, 54, 56, 71], "float32": [7, 36, 37, 38, 50, 51, 67, 69, 71], "given": [7, 14, 27, 32, 69], "classmethod": [7, 14, 71], "from_hp_to_floatx": 7, "input_float": [7, 14, 21, 22, 23, 24, 25, 26, 55], "layout": [7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 44, 45, 46, 62, 69], "scale_dtyp": [7, 21, 24, 32, 34], "from_hp_to_floatx_stat": 7, "static": [7, 12, 16, 22, 25, 34, 41], "from_hp_to_fpx": 7, "ebit": [7, 23, 33, 37, 43, 51], "mbit": [7, 23, 33, 37, 43, 51], "support": [7, 23, 40, 45, 62, 66, 67, 69, 71], "float1": [7, 23], "float7": [7, 23], "from_hp_to_intx": [7, 14], "mapping_typ": [7, 24, 32, 34, 45], "mappingtyp": [7, 24, 32, 34, 45, 46], "ep": [7, 24, 32, 34], "zero_point_dtyp": [7, 24, 32, 34, 49], "preserve_zero": [7, 24, 32, 34, 44, 49], "bool": [7, 24, 31, 32, 34, 35, 49, 53, 62], "plainlayout": [7, 24, 25, 45, 46], "use_hqq": [7, 24, 44, 56], "from_hp_to_intx_stat": 7, "kwarg": [7, 57, 58, 59, 71], "perform": [7, 19, 31, 48, 52, 53, 57, 66, 69, 71], "correct": [7, 15], "desir": [7, 31, 38], "non_block": 7, "memory_format": 7, "preserve_format": 7, "tri": [7, 69], "asynchron": 7, "respect": [7, 69], "host": 7, "possibl": [7, 69], "pin": 7, "set": [7, 10, 31, 34, 49, 53, 58, 66, 69], "even": [7, 69], "match": [7, 36, 48, 69], "other": [7, 12, 58, 67, 69, 71, 74], "randn": [7, 66, 67, 71], "float64": 7, "5044": 7, "0005": 7, "3310": 7, "0584": 7, "cuda0": 7, "blocksiz": 8, "64": [8, 27, 35, 44, 56, 67, 71], "block": [8, 16, 58, 69], "matrix": [8, 10, 40, 41, 48, 52, 58, 66, 69], "variabl": [8, 10, 19, 20, 58, 69], "int4": [9, 11, 28, 45, 49, 62, 66, 67], "cutlass": 9, "mm_config": [10, 40, 41], "float8mmconfig": [10, 40, 41], "multipl": [10, 31, 40, 41, 48, 52, 66, 69, 71], "involv": [10, 69], "_weight_int4pack_mm_for_cpu": [11, 44], "onli": [11, 40, 42, 44, 45, 47, 49, 56, 62, 66, 67, 69, 71], "version": [11, 66, 71], "least": 11, "defin": [12, 20, 43, 57, 58, 69, 71], "It": [12, 15, 17, 19, 69, 71], "pre": [12, 15, 19, 66, 69], "post": [12, 19, 71], "addit": [12, 17, 31, 39, 69, 71], "design": [12, 15, 18], "extend": [12, 69], "behavior": 12, "conjunct": 12, "tensorimpl": 12, "custom": [12, 57, 63, 66, 69, 71], "qqq": [13, 14, 26], "marlinqqq": 14, "inherit": [14, 17, 71], "choose_qparams_and_quantize_affine_qqq": 14, "dequantize_affine_qqq": 14, "ensur": 15, "preprocess": [15, 18], "manag": 15, "pre_process": 15, "1\u00ba": 15, "layer": [15, 31, 40, 42, 44, 46, 47, 53, 54, 56, 58, 59, 60, 69, 71], "weight": [15, 16, 31, 40, 41, 42, 44, 45, 46, 47, 49, 56, 58, 60, 61, 62, 63, 66, 67, 69, 71], "2\u00ba": 15, "inject": 15, "3\u00ba": 15, "again": [15, 16, 69], "dim": [15, 71], "tensor_meta": 16, "subclasstensorarg": 16, "n_block": 16, "scaler_block_s": [16, 27], "quantized_scal": 16, "quantization_factor": 16, "scaler_mean": 16, "quantized_data": 16, "nf4": 16, "qlora": 16, "convert_to_norm_float_weight": 16, "normal": [16, 27, 31, 69], "dequantize_scal": 16, "doubl": 16, "scaler": 16, "per_scaler_block": 16, "factor": [16, 48, 54, 69], "inpt_weight": 16, "double_quantize_scal": 16, "achiev": [16, 69, 71], "absmax": 16, "find": [16, 69], "posit": 16, "per_block": 16, "int16": 16, "n_scaler_block": 16, "get_original_weight": 16, "quantize_tensor_nearest": 16, "float16": [16, 35, 38, 50, 69], "nearest": 16, "round": [16, 28, 32, 71], "basic": [17, 66, 71], "add": [17, 49, 71, 74], "semi": [18, 61, 62, 69], "matric": [18, 69], "work": [18, 67, 69, 71], "everi": [18, 57, 69, 71], "four": 18, "prune": [18, 58], "conform": 18, "inner_k_til": [19, 44, 66], "effici": [19, 66, 69], "function": [19, 31, 35, 49, 57, 58, 59, 62, 66, 67, 69, 71], "affect": [19, 69], "pack_dim": [20, 56], "smaller": [20, 44, 45, 56, 66, 67], "bit": [20, 27, 43, 51, 56, 71], "width": 20, "byte": [20, 43, 56], "uintxtensor": 20, "object": [20, 71], "determin": [20, 32, 38, 44, 69], "along": [20, 69], "indic": [20, 30, 32, 69], "last": 20, "256": [27, 44], "name": [28, 29, 30, 49, 54, 58, 62, 69, 71], "modul": [28, 29, 30, 31, 49, 53, 54, 57, 58, 62, 66, 67], "qualnam": [28, 29, 30], "boundari": [28, 29, 30], "number": [28, 31, 51, 56, 58, 69, 71], "symmetr": [28, 32, 40, 41, 42, 45, 46, 47, 60, 71], "rang": [28, 69], "5": [28, 54, 58, 66, 69, 74], "7": [28, 32], "symmetric_no_clipping_err": 28, "variant": [28, 34, 71], "smin": 28, "smax": 28, "min_val_neg": [28, 71], "max_val_po": [28, 71], "By": [28, 69], "individu": [28, 69], "less": [28, 32, 69, 71], "error": [28, 31, 71], "neg": 28, "placehold": 29, "yet": [29, 45, 71], "enum": 30, "whether": [30, 31, 32, 44, 49, 56, 71], "quantized_v": 30, "float_val": 30, "mid_point": 30, "example_input": [31, 66, 67], "qtensor_class_list": 31, "aqdefaultlinearweight": 31, "aqint8weightonlyquantizedlinearweight": 31, "aqint8weightonlyquantizedlinearweight2": 31, "aqint8dynamicallyquantizedlinearweight": 31, "filter_fn": [31, 49, 62], "interpol": 31, "85": 31, "manual": [31, 49], "set_inductor_config": [31, 49], "supress_autoquant_error": 31, "min_sqnr": 31, "aq_kwarg": 31, "autoquant": 31, "identifi": 31, "fastest": 31, "over": [31, 69], "potenti": [31, 69], "qtensor": 31, "search": [31, 69], "whose": 31, "exchang": 31, "autoquantizablelinearweight": 31, "calibr": [31, 34], "activ": [31, 40, 41, 45, 46, 53, 58, 60, 63, 69], "seen": 31, "benchmark": [31, 53], "member": 31, "pick": 31, "highli": 31, "complet": 31, "simpli": [31, 69, 71], "had": [31, 71], "compil": [31, 49, 52, 66, 71], "case": [31, 52, 69, 71], "onc": [31, 69], "proce": 31, "combin": [31, 69, 71], "finalize_autoqu": 31, "been": [31, 71], "log": [31, 71], "fulli": [31, 49, 54, 62, 69], "unless": 31, "default_autoquant_class_list": 31, "callabl": [31, 35, 49, 55, 62], "contain": [31, 53, 54, 69, 71], "stop": 31, "sever": 31, "automat": [31, 49, 71, 74], "config": [31, 49, 58, 69], "suppress": 31, "accept": 31, "signal": 31, "nois": 31, "ration": 31, "wikipedia": 31, "wiki": 31, "noise_ratio": 31, "v": 31, "impact": 31, "caus": 31, "too": 31, "larg": [31, 71], "numer": [31, 69], "resaon": 31, "40": 31, "adjust": 31, "keyword": 31, "usag": 31, "example_input1": 31, "example_input2": 31, "fp32": [32, 36, 71], "fp16": 32, "optioanl": 32, "flag": 32, "exactli": [32, 44, 71], "pad": 32, "convolut": 32, "doesn": [32, 69], "itself": [32, 69, 71], "loss": [32, 69], "won": [32, 71], "gurante": 32, "don": [32, 58, 66, 69], "clamp": [32, 71], "request": [32, 36, 50], "observ": [34, 57, 69], "obtain": 34, "param": [34, 39, 58], "nbit": 35, "group_siz": [35, 44, 45, 47, 49, 56, 66], "axi": [35, 50], "compute_dtyp": 35, "str": [35, 49, 54, 55, 58, 62, 71], "verbos": 35, "raw_output": 35, "optimize_weight": 35, "optimize_weights_proximal_legaci": 35, "input_dtyp": 36, "output_dtyp": [36, 37, 50], "quant_dtyp": [38, 39], "fake": [38, 39], "awar": [38, 39, 58, 69, 71], "train": [38, 39, 63, 69, 71], "equival": [38, 39, 54, 69], "cast": [38, 39], "valid": 38, "fake_quantize_affin": 39, "consum": 39, "outlier": 39, "mask": [39, 58, 69], "intermedi": 39, "activation_dtyp": [40, 41], "weight_dtyp": [40, 41, 42], "pertensor": [40, 41], "perrow": [40, 41], "dynam": [40, 45, 46, 62, 71], "current": [40, 45, 49, 54, 58, 62, 69, 71], "fast": [40, 41, 69], "accumul": [40, 41], "float8_e4m": 41, "channel": [42, 46, 47, 57, 60], "sub": [43, 56, 69], "expon": [43, 51], "mantissa": [43, 51], "fp6_e3_m2": 43, "fp6_e2_m3": 43, "fp6": 43, "llm": 43, "paper": [43, 69, 74], "arxiv": [43, 58, 69], "ab": [43, 58, 69], "2401": 43, "14112": 43, "repo": 43, "usyd": 43, "fsalab": 43, "fp6_llm": 43, "renam": 43, "fpxtensorcoreaqttensorimpl": 43, "experiment": 43, "merg": 43, "to_affine_quantized_floatx": 43, "128": [44, 71], "int4mm": [44, 66], "algorithm": [44, 56, 69], "tradit": 44, "chosen": [44, 69], "control": [44, 45, 56, 58, 69], "grain": [44, 45, 56, 71], "choic": 44, "32": [44, 45, 49, 62, 66, 67, 71], "act_mapping_typ": [45, 46], "token": [45, 46, 60], "produc": 45, "backend": [45, 69], "did": 45, "flow": [45, 69], "marlinqqqlayout": 45, "cutlassint4packedlayout": 45, "weight_only_decod": 46, "b": 48, "scales1": 48, "multipli": [48, 52, 69], "row": [48, 69], "rais": [48, 52, 71], "assertionerror": [48, 52, 71], "expect": [48, 69, 71], "inplac": [49, 58, 66], "instanc": [49, 57, 62, 67, 71], "qualifi": [49, 54, 62, 69], "speed": [49, 69], "predefin": 49, "execut": [49, 68, 71, 73], "path": [49, 52, 66], "customiz": 49, "int8_dynamic_activation_int4_weight": 49, "int8_dynamic_activation_int8_weight": [49, 62], "mm": [49, 71], "int8_weight_onli": 49, "sequenti": [49, 62], "1024": [49, 62, 66, 67], "constructor": [49, 71], "groupwis": 49, "groupsiz": [49, 50], "apply_weight_qu": 49, "lambda": 49, "x": [49, 56, 66, 67, 71, 74], "15": [49, 66], "1e": 49, "apply_weight_quant_to_linear": 49, "block0": 49, "submodul": 49, "fqn": [49, 58, 62], "isinst": [49, 62, 69, 71], "per_tensor": 50, "per_axi": 50, "per_group": 50, "low": [51, 69, 71], "00seeemm": 51, "fp6_e3m2": 51, "sign": 51, "mat2": 52, "safe": 52, "cubla": 52, "fallback": 52, "i": [52, 69], "j": 52, "debug_skip_calibr": 53, "smoothquant": [53, 54], "smoothfakedynamicallyquantizedlinear": [53, 54], "debug": 53, "skip_fqn_list": 54, "cur_fqn": 54, "alpha": 54, "replac": [54, 69], "skip": [54, 58, 69], "quant_kwarg": 55, "dict": [55, 58, 71], "l2": [57, 69], "norm": [57, 58, 69], "buffer": 57, "x_orig": 57, "overridden": 57, "although": [57, 71], "recip": 57, "within": [57, 69], "afterward": 57, "former": 57, "care": [57, 67, 69], "while": [57, 58, 69, 71], "latter": 57, "silent": 57, "ignor": 57, "sparsity_level": [58, 69], "semi_structured_block_s": 58, "wanda": 58, "sparsifi": [58, 63, 67, 69], "propos": 58, "2306": 58, "11695": 58, "product": 58, "magnitud": [58, 69], "level": [58, 69, 71], "parametr": 58, "preserv": [58, 69], "deepcopi": [58, 66, 71], "squash_mask": [58, 69], "params_to_keep": 58, "params_to_keep_per_lay": 58, "squash": 58, "sparse_param": 58, "attach": [58, 69], "kei": [58, 69, 74], "save": [58, 66, 67], "string": 58, "xdoctest": 58, "local": [58, 69], "undefin": 58, "hasattr": 58, "submodule1": 58, "linear1": [58, 66, 67, 71], "foo": 58, "bar": 58, "submodule2": 58, "linear42": 58, "baz": 58, "print": [58, 66, 67, 71, 74], "42": 58, "24": 58, "update_mask": 58, "tensor_nam": 58, "retriev": 58, "act_per_input": 58, "Then": [58, 71], "metric": 58, "across": [58, 69, 71], "whole": 58, "dnynam": 60, "moduel": 61, "sparsify_": 62, "essenti": 62, "semi_sparse_weight": 62, "semisparselayout": 62, "sparsemarlinlayout": 62, "sparse_api": 62, "librari": [63, 67], "gradient": [63, 69], "nativ": [63, 71], "readm": [63, 66, 69], "overal": [63, 66], "recent": 63, "highlight": [63, 71, 74], "updat": [63, 66, 67, 69], "guid": 63, "overview": [63, 66], "contributor": [63, 66], "serial": 63, "advanc": [63, 71], "soon": [65, 70], "explor": 66, "instal": 66, "latest": 66, "stabl": 66, "releas": 66, "pip": 66, "nightli": 66, "command": 66, "index": [66, 69], "url": 66, "download": [66, 72, 74], "whl": 66, "cu121": 66, "major": 66, "instruct": 66, "entri": 66, "mutat": 66, "insert": 66, "logic": [66, 71], "toi": [66, 71], "toylinearmodel": [66, 67], "__init__": [66, 67, 71], "super": [66, 67, 71], "linear2": [66, 67, 71], "eval": [66, 67], "faster": [66, 69], "model_bf16": 66, "leverag": [66, 71], "mix": 66, "readi": [66, 71], "in_featur": [66, 67, 71], "out_featur": [66, 71], "tensor_impl_dtyp": 66, "verifi": [66, 67, 71], "roughli": [66, 69], "quarter": 66, "os": 66, "tmp": 66, "int4_model": 66, "pt": 66, "bfloat16_model": 66, "int4_model_size_mb": 66, "getsiz": 66, "bfloat16_model_size_mb": 66, "2f": 66, "mb": [66, 67, 68, 73], "25": 66, "00": [66, 68, 73], "much": [66, 69], "torch_version_at_least_2_5": 66, "benchmark_model": 66, "temporari": 66, "workaround": 66, "num_run": 66, "100": [66, 71], "_dynamo": [66, 71], "reset": 66, "bf16_time": 66, "int4_tim": 66, "time": [66, 69, 71, 74], "3f": 66, "ms": 66, "1fx": 66, "a100": 66, "gpu": [66, 74], "80gb": 66, "30": 66, "393": 66, "410": 66, "9x": 66, "simpl": [66, 69, 71], "workflow": [66, 69], "visit": 66, "page": 66, "would": [66, 69, 71], "forget": 66, "good": [66, 71], "tempfil": 67, "get_model_size_in_byt": 67, "batch_siz": 67, "ref": 67, "namedtemporaryfil": 67, "state_dict": 67, "seek": [67, 69], "load": 67, "meta": 67, "m_load": 67, "load_state_dict": 67, "assign": 67, "re": [67, 71], "assert": [67, 71], "equal": [67, 69], "float_weight1": 67, "float_weight2": 67, "quantized_weight1": 67, "quantized_weight2": 67, "go": [67, 71, 74], "techinqu": 67, "implement": [67, 69], "reduct": [67, 69, 71], "around": 67, "4x": 67, "0625": 67, "reason": [67, 69], "avoid": [67, 69], "properli": 67, "003": [68, 73, 74], "total": [68, 73, 74], "galleri": [68, 72, 74], "mem": [68, 73], "templat": [68, 72, 73], "tutorials_sourc": 68, "template_tutori": [68, 73, 74], "neural": 69, "network": [69, 71], "reduc": 69, "its": [69, 71], "overhead": 69, "latenc": 69, "carefulli": 69, "signific": 69, "pai": 69, "price": 69, "qualiti": 69, "accuraci": 69, "f1": 69, "problem": [69, 71], "research": [69, 74], "face": 69, "fragment": 69, "rightfulli": 69, "spent": 69, "compress": 69, "place": 69, "dens": 69, "solv": [69, 71], "focu": [69, 71], "realli": 69, "push": 69, "accur": 69, "concret": 69, "hope": 69, "modular": 69, "acceler": 69, "compos": [69, 71], "scratch": [69, 74], "minim": 69, "recov": 69, "algorthim": 69, "realiz": 69, "improv": 69, "trade": 69, "off": 69, "degrad": 69, "architectur": 69, "theoret": 69, "gain": 69, "2x": 69, "analog": 69, "fix": 69, "50": 69, "unstructur": 69, "One": [69, 71], "howev": 69, "close": 69, "relat": 69, "mitig": 69, "retrain": 69, "neglig": 69, "area": 69, "agre": 69, "upon": 69, "consensu": 69, "mind": 69, "thought": 69, "separ": 69, "subproblem": 69, "satisfi": 69, "consist": [69, 71], "answer": 69, "independ": 69, "frontend": 69, "arbitrari": 69, "handoff": 69, "piec": 69, "miss": 69, "natur": [69, 71], "present": 69, "clear": 69, "contract": 69, "7x": 69, "advantag": 69, "anticip": 69, "mani": [69, 71], "solut": 69, "third": 69, "parti": 69, "to_sparse_semi_structur": 69, "sparsesemistructuredtensor": 69, "weightnormsparsifi": 69, "half": 69, "subnetwork": 69, "sparse_config": 69, "mod": [69, 71], "named_modul": 69, "append": 69, "tensor_fqn": 69, "sparse_block_shap": 69, "zeros_per_block": 69, "fakespars": 69, "manipul": 69, "dictionari": 69, "paramer": 69, "parameter": 69, "necessari": [69, 71], "ve": 69, "suitabl": 69, "fuse": [69, 71], "0s": 69, "spot": 69, "definit": 69, "academia": 69, "industri": 69, "often": [69, 71], "interchang": 69, "refer": [69, 71], "confus": 69, "distinct": 69, "pretrain": 69, "behind": 69, "box": 69, "those": [69, 71], "loos": 69, "speak": 69, "tightli": 69, "coupl": [69, 71], "nvidia": 69, "csc": 69, "fbgemm": 69, "qnnpack": 69, "descript": 69, "coordin": 69, "vector": 69, "locat": 69, "bsr": 69, "sparse_bsr": 69, "except": [69, 71], "scalar": 69, "csr": 69, "sparse_csr": 69, "sparse_csc": 69, "column": 69, "compact": 69, "sparse_matrix": 69, "1d": 69, "indexptr": 69, "\u00bd": 69, "bitmask": 69, "2bit": 69, "unprun": 69, "quit": [69, 71], "must": 69, "successfulli": 69, "These": [69, 71], "broken": 69, "down": 69, "Not": 69, "sensit": 69, "effect": [69, 71], "best": 69, "subsequ": [69, 71], "infinit": 69, "lost": 69, "degre": 69, "analysi": 69, "drop": 69, "give": [69, 71], "curv": 69, "proxi": 69, "aforement": 69, "smallest": 69, "absolut": 69, "vs": 69, "global": [69, 71], "scope": 69, "impli": 69, "pro": 69, "con": 69, "tradeoff": 69, "span": 69, "threshold": 69, "increas": 69, "complex": 69, "constant": [69, 71], "ctr_mobile_fe": 69, "score": 69, "w": 69, "tenosr": 69, "udpat": 69, "cannot": 69, "histori": 69, "regrow": 69, "dw": 69, "via": 69, "backprop": 69, "pat": 69, "unmask": 69, "resid": 69, "backward": 69, "salienc": 69, "lowest": 69, "l1": 69, "commonli": 69, "shown": 69, "abl": [69, 71], "ident": 69, "repeat": 69, "loop": 69, "shot": 69, "movement": 69, "inform": 69, "tune": 69, "2005": 69, "07683": 69, "rank": [69, 71], "wx": 69, "sqx": 69, "q": 69, "usual": 69, "sort": 69, "wise": 69, "reconstruct": 69, "random": 69, "randomli": 69, "remedi": 69, "line": 69, "item": [69, 74], "ultim": 69, "literatur": 69, "vision": 69, "nlp": [69, 74], "iter": 69, "ctr_feed": 69, "na": 69, "multimask": 69, "pyspeech": 69, "fastna": 69, "approach": [69, 71], "knowledg": [69, 74], "distil": 69, "pdf": 69, "2204": 69, "09656": 69, "arrang": 69, "recal": 69, "counterpart": 69, "slower": 69, "suffici": 69, "flexibl": [69, 71], "98": 69, "benefit": [69, 71], "special": 69, "exhibit": 69, "maintain": 69, "penalti": 69, "expens": [69, 71], "dictat": 69, "characterist": 69, "highest": 69, "wouldn": [69, 71], "visual": 69, "fig": 69, "4x4": 69, "benchmak": 69, "foundat": 71, "extens": 71, "featur": 71, "autograd": 71, "distribut": 71, "express": 71, "interpos": 71, "namespac": 71, "continu": 71, "seamlessli": 71, "obviou": 71, "int8quantizedlinear": 71, "few": 71, "finer": 71, "intercept": 71, "slightli": 71, "contrast": 71, "long": 71, "better": 71, "clunki": 71, "distributedlinear": 71, "duplic": 71, "bypass": 71, "offer": 71, "outer": 71, "inner": 71, "allgath": 71, "bandwidth": 71, "rest": 71, "read": 71, "document": 71, "zoo": 71, "podcast": 71, "edward": 71, "yang": 71, "begin": 71, "int8_symmetric_quant": 71, "fp32_tensor": 71, "127": 71, "amin": 71, "keepdim": 71, "amax": 71, "zeros_lik": 71, "quantizedlinear": 71, "w_int8": 71, "cl": 71, "new_linear": 71, "left": 71, "toymodel": 71, "float_model": 71, "quantized_model": 71, "child": 71, "named_children": 71, "setattr": 71, "drawback": 71, "suppos": 71, "clean": 71, "limit": 71, "eleg": 71, "pretti": 71, "power": 71, "overrid": 71, "almost": 71, "shard": 71, "ragged": 71, "rag": 71, "nestedtensor": 71, "resourc": 71, "who": 71, "link": [71, 74], "googl": 71, "collab": 71, "flopcount": 71, "memorytrack": 71, "With": 71, "bare": 71, "bone": 71, "int8symmetrictensor": 71, "hold": 71, "staticmethod": 71, "disabl": 71, "__new__": 71, "_make_wrapper_subclass": 71, "storage_offset": 71, "ndim": 71, "__tensor_flatten__": 71, "attribut": 71, "pt2": 71, "__tensor_unflatten__": 71, "tensor_data_dict": 71, "extra_metadata": 71, "outer_s": 71, "outer_strid": 71, "undo": 71, "back": 71, "__repr__": 71, "repr": 71, "ahead": 71, "insid": 71, "int8_tensor": 71, "func": 71, "op_implementations_dict": 71, "conveni": 71, "register_op": 71, "_op": 71, "opoverload": 71, "impl_decor": 71, "op_impl": 71, "wrapper": 71, "particular": 71, "largest": 71, "tell": 71, "desugar": 71, "decor": 71, "surfac": 71, "coverag": 71, "though": 71, "brute": 71, "forc": 71, "repeatedli": 71, "loggingtensor": 71, "_python_dispatch": 71, "return_and_correct_alias": 71, "int8_mm": 71, "detach": 71, "int8_view_op": 71, "out_data": 71, "out_scal": 71, "notic": 71, "quickli": 71, "hit": 71, "background": 71, "decomposit": 71, "live": 71, "decomp": 71, "shrink": 71, "author": [71, 74], "pain": 71, "rather": 71, "underli": 71, "worth": 71, "written": 71, "differenti": 71, "nuanc": 71, "longer": 71, "That": 71, "transposit": 71, "got": 71, "propag": 71, "fact": 71, "themselv": 71, "pointwis": 71, "alwai": 71, "were": 71, "might": 71, "unwrap": 71, "dim0": 71, "dim1": 71, "confirm": 71, "quantized_model_module_swap": 71, "quantized_model_subclass": 71, "subclass_param": 71, "no_grad": 71, "out_module_swap": 71, "allclos": 71, "out_compil": 71, "seri": 71, "wa": 71, "tutorials_python": 72, "zip": [72, 74], "jupyt": [72, 74], "notebook": [72, 74], "tutorials_jupyt": 72, "sphinx": [72, 74], "firstnam": 74, "lastnam": 74, "prerequisit": 74, "v2": 74, "topic": 74, "rand": 74, "9722": 74, "8233": 74, "2598": 74, "4688": 74, "2634": 74, "0506": 74, "4384": 74, "3901": 74, "3965": 74, "8985": 74, "4440": 74, "7220": 74, "0670": 74, "3436": 74, "4372": 74, "practic": 74, "test": 74, "summar": 74, "takeawai": 74, "link1": 74, "link2": 74, "minut": 74, "ipynb": 74}, "objects": {"torchao.dtypes": [[7, 0, 1, "", "AffineQuantizedTensor"], [8, 0, 1, "", "BlockSparseLayout"], [9, 0, 1, "", "CutlassInt4PackedLayout"], [10, 0, 1, "", "Float8Layout"], [11, 0, 1, "", "Int4CPULayout"], [12, 0, 1, "", "Layout"], [13, 0, 1, "", "MarlinQQQLayout"], [14, 0, 1, "", "MarlinQQQTensor"], [15, 0, 1, "", "MarlinSparseLayout"], [16, 0, 1, "", "NF4Tensor"], [17, 0, 1, "", "PlainLayout"], [18, 0, 1, "", "SemiSparseLayout"], [19, 0, 1, "", "TensorCoreTiledLayout"], [20, 0, 1, "", "UintxLayout"], [21, 2, 1, "", "to_affine_quantized_floatx"], [22, 2, 1, "", "to_affine_quantized_floatx_static"], [23, 2, 1, "", "to_affine_quantized_fpx"], [24, 2, 1, "", "to_affine_quantized_intx"], [25, 2, 1, "", "to_affine_quantized_intx_static"], [26, 2, 1, "", "to_marlinqqq_quantized_intx"], [27, 2, 1, "", "to_nf4"]], "torchao.dtypes.AffineQuantizedTensor": [[7, 1, 1, "", "dequantize"], [7, 1, 1, "", "from_hp_to_floatx"], [7, 1, 1, "", "from_hp_to_floatx_static"], [7, 1, 1, "", "from_hp_to_fpx"], [7, 1, 1, "", "from_hp_to_intx"], [7, 1, 1, "", "from_hp_to_intx_static"], [7, 1, 1, "", "to"]], "torchao.dtypes.MarlinQQQTensor": [[14, 1, 1, "", "dequantize"], [14, 1, 1, "", "from_hp_to_intx"]], "torchao.dtypes.MarlinSparseLayout": [[15, 1, 1, "", "pre_process"]], "torchao.dtypes.NF4Tensor": [[16, 1, 1, "", "convert_to_norm_float_weight"], [16, 1, 1, "", "dequantize"], [16, 1, 1, "", "dequantize_scalers"], [16, 1, 1, "", "double_quantize_scalers"], [16, 1, 1, "", "get_original_weight"], [16, 1, 1, "", "quantize_tensor_nearest"]], "torchao.quantization": [[28, 0, 1, "", "MappingType"], [29, 0, 1, "", "TorchAODType"], [30, 0, 1, "", "ZeroPointDomain"], [31, 2, 1, "", "autoquant"], [32, 2, 1, "", "choose_qparams_affine"], [33, 2, 1, "", "choose_qparams_affine_floatx"], [34, 2, 1, "", "choose_qparams_affine_with_min_max"], [35, 2, 1, "", "choose_qparams_and_quantize_affine_hqq"], [36, 2, 1, "", "dequantize_affine"], [37, 2, 1, "", "dequantize_affine_floatx"], [38, 2, 1, "", "fake_quantize_affine"], [39, 2, 1, "", "fake_quantize_affine_cachemask"], [40, 2, 1, "", "float8_dynamic_activation_float8_weight"], [41, 2, 1, "", "float8_static_activation_float8_weight"], [42, 2, 1, "", "float8_weight_only"], [43, 2, 1, "", "fpx_weight_only"], [44, 2, 1, "", "int4_weight_only"], [45, 2, 1, "", "int8_dynamic_activation_int4_weight"], [46, 2, 1, "", "int8_dynamic_activation_int8_weight"], [47, 2, 1, "", "int8_weight_only"], [48, 2, 1, "", "int_scaled_matmul"], [49, 2, 1, "", "quantize_"], [50, 2, 1, "", "quantize_affine"], [51, 2, 1, "", "quantize_affine_floatx"], [52, 2, 1, "", "safe_int_mm"], [53, 2, 1, "", "smooth_fq_linear_to_inference"], [54, 2, 1, "", "swap_linear_with_smooth_fq_linear"], [55, 2, 1, "", "to_linear_activation_quantized"], [56, 2, 1, "", "uintx_weight_only"]], "torchao": [[4, 3, 0, "-", "sparsity"]], "torchao.sparsity": [[57, 0, 1, "", "PerChannelNormObserver"], [58, 0, 1, "", "WandaSparsifier"], [59, 2, 1, "", "apply_fake_sparsity"], [60, 2, 1, "", "int8_dynamic_activation_int8_semi_sparse_weight"], [61, 2, 1, "", "semi_sparse_weight"], [62, 2, 1, "", "sparsify_"]], "torchao.sparsity.PerChannelNormObserver": [[57, 1, 1, "", "forward"]], "torchao.sparsity.WandaSparsifier": [[58, 1, 1, "", "prepare"], [58, 1, 1, "", "squash_mask"], [58, 1, 1, "", "update_mask"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "module", "Python module"]}, "titleterms": {"torchao": [0, 1, 2, 3, 4, 5, 63], "dtype": [0, 5, 6], "layout": [0, 5, 12], "tensor": [0, 5, 70, 71], "subclass": [0, 5, 71], "quantiz": [0, 3, 5, 49, 65, 66, 70, 71], "techniqu": 0, "api": [1, 63], "refer": [1, 63], "python": 1, "kernel": [2, 5, 64], "sparsiti": [4, 69], "contributor": 5, "guid": [5, 66], "object": 5, "stack": 5, "overview": [5, 65, 69, 74], "basic": 5, "current": 5, "support": 5, "ad": 5, "placehold": 5, "pytorch": 5, "implement": [5, 71], "oper": [5, 71], "integr": 5, "nativ": 5, "factori": 5, "function": 5, "primit": 5, "op": 5, "effici": 5, "deriv": 5, "tensorimpl": 5, "algorithm": 5, "flow": [5, 67], "weight": 5, "onli": 5, "dynam": 5, "activ": 5, "static": 5, "insert": 5, "observ": 5, "how": 5, "defin": 5, "modul": [5, 71], "add": 5, "model": [5, 67], "calibr": 5, "other": 5, "train": 5, "awar": 5, "low": 5, "bit": 5, "optim": [5, 67], "case": 5, "studi": 5, "int4": 5, "work": 5, "high": 5, "level": 5, "summari": 5, "dure": 5, "execut": 5, "save": 5, "load": 5, "custom": 5, "triton": 5, "hand": 5, "written": 5, "dispatch": 5, "us": 5, "torch": 5, "compil": 5, "perform": [5, 64], "serial": [5, 67], "featur": 5, "gener": 5, "extend": 5, "compos": 5, "test": 5, "microbenchmark": 5, "benchmark": 5, "eval": 5, "affinequantizedtensor": 7, "blocksparselayout": 8, "cutlassint4packedlayout": 9, "float8layout": 10, "int4cpulayout": 11, "marlinqqqlayout": 13, "marlinqqqtensor": 14, "marlinsparselayout": 15, "nf4tensor": 16, "plainlayout": 17, "semisparselayout": 18, "tensorcoretiledlayout": 19, "uintxlayout": 20, "to_affine_quantized_floatx": 21, "to_affine_quantized_floatx_stat": 22, "to_affine_quantized_fpx": 23, "to_affine_quantized_intx": 24, "to_affine_quantized_intx_stat": 25, "to_marlinqqq_quantized_intx": 26, "to_nf4": 27, "mappingtyp": 28, "torchaodtyp": 29, "zeropointdomain": 30, "autoqu": 31, "choose_qparams_affin": 32, "choose_qparams_affine_floatx": 33, "choose_qparams_affine_with_min_max": 34, "choose_qparams_and_quantize_affine_hqq": 35, "dequantize_affin": 36, "dequantize_affine_floatx": 37, "fake_quantize_affin": 38, "fake_quantize_affine_cachemask": 39, "float8_dynamic_activation_float8_weight": 40, "float8_static_activation_float8_weight": 41, "float8_weight_onli": 42, "fpx_weight_onli": 43, "int4_weight_onli": 44, "int8_dynamic_activation_int4_weight": 45, "int8_dynamic_activation_int8_weight": 46, "int8_weight_onli": 47, "int_scaled_matmul": 48, "quantize_affin": 50, "quantize_affine_floatx": 51, "safe_int_mm": 52, "smooth_fq_linear_to_infer": 53, "swap_linear_with_smooth_fq_linear": 54, "to_linear_activation_quant": 55, "uintx_weight_onli": 56, "perchannelnormobserv": 57, "wandasparsifi": 58, "apply_fake_spars": 59, "int8_dynamic_activation_int8_semi_sparse_weight": 60, "semi_sparse_weight": 61, "sparsifi": 62, "welcom": 63, "document": 63, "get": 63, "start": [63, 66], "develop": 63, "note": 63, "tutori": [63, 74], "quick": 66, "first": 66, "exampl": 66, "next": [66, 71], "step": [66, 71, 74], "deseri": 67, "what": [67, 71], "happen": 67, "when": 67, "an": 67, "comput": [68, 73], "time": [68, 73], "goal": 69, "design": 69, "context": 69, "prune": 69, "configur": 69, "criteria": 69, "strategi": 69, "pattern": 69, "write": [70, 71], "your": [70, 71], "own": [70, 71], "advanc": 70, "ar": 71, "swap": 71, "which": 71, "should": 71, "we": 71, "compar": 71, "output": 71, "templat": 74, "option": 74, "addit": 74, "exercis": 74, "conclus": 74, "further": 74, "read": 74}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})